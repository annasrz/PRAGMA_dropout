---
title: "QWT_dropout"
author: "Anna"
date: "2024-06-18"
output: 
  html_document:
    code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(warn = -1)
```

# Vorbereitungen

```{r essentials}
# clean workspace
rm(list=ls())
packages <- c("data.table", "tidyverse", "ggplot2", "glmmTMB", "comorbidity", "car", "lme4", "ordinal", "export", "mclogit", "sjPlot")

# Install packages not yet installed
installed_packages <- packages %in% rownames(installed.packages())
if (any(installed_packages == FALSE)) {
  install.packages(packages[!installed_packages])
}
# Load packages
invisible(lapply(packages, library, character.only = TRUE))

# current date:
DATE <- format(Sys.Date(), "%Y%m%d")

# themes and options
options(scipen = 999)

# output folders
folder_table <- file.path("..", "output/tables")
folder_plot <- file.path("..", "output/figures")

if (!file.exists(folder_table)) {
  dir.create(folder_table, recursive = TRUE)
}

if (!file.exists(folder_plot)) {
  dir.create(folder_plot, recursive = TRUE)
}
```

# Daten Import

```{r data_import}
print(getwd())
datapath <- file.path("..", "input") 
#read in all files in datapath 
filenames <- list.files(datapath, pattern = "\\.rds$", full.names = T)

#save all files as separate dataframes
ldf <- lapply(filenames, readRDS)
names(ldf) <- gsub(".rds", "", basename(filenames))
print(names(ldf))
names <- c("pragma_id_GKV", "alc_diagnoses", "all_diagnoses", "medications", "employment", "fosterage", "income", "insurance_periods", "inpat_OPS", "inpat", "qwt_OPS", "qwt", "reha")
names(ldf) <- names
#check if all dataframes are loaded
ls()
list2env(ldf, envir = .GlobalEnv) #save all dataframes in global environment as dataframes
rm(ldf)
```

# Outcome Variablen Definition 

## ENTLASS301
```{r recode_ENTL}
table(qwt$ENTL301)
str(qwt$ENTL301)
#QWT as factor with new labels
qwt$ENTL301 <- factor(qwt$ENTL301, levels = c(1, 2, 3, 4, 6, 7, 9, 10, 13, 14, 15, 17, 22), labels = c("regulär", "beendet, nachstat. Beh. vorgesehen", "aus sonstigen Gründen beendet", "gegen ärztlichen Rat beendet", "Verlegung in ein anderes Krankenhaus", "Tod", "Rehaeinrichtung",
"Pflegeeinrichtung", "externe Verlegung zur psychiatrischen Behandlung", "aus sonst. Gründen beend., nachstat. Beh. Vorges.", "gegen ärztlichen Rat beendet, nachstat. Beh. vorgeseh.", "interne Verlegung m. Wechsel zw. D. Gelt.b. BPflV u. KHEntgG", "Fallabschl. (int. V.) b. Wechsel zw. Voll- und teilst. Beh."))
#was passiert nach interne Verlegung m. Wechsel zw. D. Gelt.b. BPflV u. KHEntgG?
```

## Validierung der ENTLASS301 Variable an Behandlungsdauer

```{r check_ENTL301}
prop.table(table(qwt$ENTL301))

ggplot(qwt, aes(x = ENTL301)) + geom_bar() + theme(axis.text.x = element_text(angle = 25, hjust = 1))

#add Anzahl Tage in Behandlung
qwt <- qwt %>% 
    mutate(n_days = as.integer(difftime(as.Date(date.qwt.end), as.Date(date.qwt.start), units = "days")) + 1)

```

```{r ENTL301_ndays_dist}

ENTL_ndays <- ggplot(qwt %>% filter (ENTL301 != "Tod"), aes(x = ENTL301, y = n_days)) + 
  geom_jitter(alpha=0.1, size = rel(0.8), ) +
  geom_boxplot(width = 0.2, outlier.shape = NA) +
  scale_y_continuous(breaks = seq(0, 100, by = 5)) +
  #change y axis label
  ylab("Anzahl Tage in QE") +
  xlab("Entlassungsgrund (ENTL301)") +
  #change legend title
  labs(title = "Dauer eines Qualifizierten Entzugs nach Entlassungsgrund unter GKV Versicherten", caption = "Anmerk.: Datenpunkte markieren einzelne Behandlungen") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 35, hjust = 1, size = rel(0.85))) +
  theme(legend.position = "top")
  

ENTL_ndays
graph2doc(x = ENTL_ndays, file=file.path(folder_plot, "ENTL_ndays.png"), width=7, height=5)
ggsave(file.path(folder_plot, "ENTL_ndays.png"), ENTL_ndays, width = 10, height = 6)

#calculate IQR for n_days only among regulär beendeten Behandlungen
qwt %>% 
  filter(ENTL301 == "regulär") %>%
  summarise(q25 = quantile(n_days, 0.25), q75 = quantile(n_days, 0.75), iqr = IQR(n_days), min = min(n_days), max = max(n_days))

```

Die Variable ENTL301 gibt den Entlassungsgrund an. Die meisten Behandlungen werden regulär beendet, wobei auffällig ist, dass es unter diesen viele Behandlungen gibt, die nur sehr kurz dauern. Außerdem gibt es eine zweigipfelige Verteilung der Behandlungsdauer bei den regulär beendeten Behandlungen mit einem Peak um eine Woche, obwohl eigentlich 21 Tage empfohlen werden. Die ENTL301-Variable scheint daher kein idealer Indikator für einen unplanmäßigen Behandlungsabbruch zu sein.

Als alternative Operationalisierung der AV Behandlungserfolg (vorher: unplanmäßger Beendigung) des Aufenthalts ziehen wir daher stattdessen die Anzahl der Tage in Behandlung an. Die Behandlungsdauer teilen wir in drei Gruppen ein: 0-6 Tage (unter Mindestaufenthalt), 7-20 Tage (Mindestaufenthalt absolviert, aber unter empfohlener Dauer) und 21+ Tage (empfohlene Dauer). 

## Behandlungsdauer als AV

```{r create vars}

# 3-stufige AV
qwt <- qwt %>%
  filter(ENTL301 != "Tod") %>%
  mutate(treat_dur_cat = factor(case_when(
  #more than or 20 days in treatment
  n_days >= 21 ~ 3,
  #between 7 and 19 days (inclusive)
  n_days >= 7 & n_days < 21 ~ 2,
  #between 0 and 6 days (inclusive)
  n_days >= 0 & n_days < 7 ~ 1,
  TRUE ~ NA_real_), levels = c(1, 2, 3), labels = c("1-6 Tage","7-20 Tage", "21+ Tage")))

# 2-stufige AV
#qwt <- qwt %>%
#  mutate(treat_dur_bin = factor(case_when(
  #more than or 20 days in treatment
#  n_days >= 21 ~ 2,
  #below 20 days (inclusive)
#  n_days < 21 ~ 1,
#  TRUE ~ NA_real_), levels = c(1, 2), labels = c("unter 21 Tage", "21+ Tage")))

```

### Verteilung der neuen AV
```{r check_treat_dur}
ggplot(qwt, aes(x = treat_dur_cat)) + geom_bar() + theme(axis.text.x = element_text(angle = 25, hjust = 1))

ggplot(qwt, aes(x = n_days)) +
  geom_histogram(binwidth = 1) +
  scale_x_continuous(limits = c(0, 30), breaks = seq(0, 30, by = 2), labels = seq(0, 30, by = 2)) 
#  scale_x_continuous(limits = c(0, 27)) 

```


# Prädiktoren

## qwt_id
```{r check_qwt_id}
# does the qwt_id increases with increasing date.qwt.start?
qwt_check <- qwt %>% 
  group_by(pragmaid) %>%
  arrange(date.qwt.start) %>%
  mutate(qwt_id_check = row_number()) %>%
  select(pragmaid, qwt_id, qwt_id_check, date.qwt.start, date.qwt.end) #qwt_id does not increase with increasing date.qwt.start. therefore, replace qwt_id with qwt_id_check

#replace qwt_id with qwt_id_check
qwt <- qwt %>% 
  group_by(pragmaid) %>%
  arrange(date.qwt.start) %>%
  mutate(qwt_id = row_number()) %>%
  ungroup()
```


## Hinzufügen der Stammdaten - SEX, AGE and nationality

```{r add_stammdaten}
#match pragma_id_GKV with qwt based on pragma_id (only columns names sex and yob)
total_stamm <- left_join(qwt, pragma_id_GKV, by="pragmaid")

total_stamm <- total_stamm %>% 
  select(c(-hivid, -gkv.id, -dak.id, -aok.id, - gkv.y)) %>%
  mutate(age = as.integer(substr(date.qwt.start, 1, 4)) - yob) %>%
  rename(gkv = gkv.x)
#4 patients with gkv aokdak (aokdak values are only present in the stamm data, but not in the qwt data, keep only gkv from qwt data)

total_stamm$pragmaid <- factor(total_stamm$pragmaid)

table(total_stamm$sex, useNA = "always")
table(total_stamm$gkv, useNA = "always")
```

## Hinzufügen Emplyoment Status

```{r add_employment}
nrow(distinct(total_stamm, pragmaid, qwt_id)) #3857
total_employ_all <- left_join(total_stamm, employment, by = "pragmaid")

# Filtern der Zeilen, sodass qwt_start innerhalb des Zeitraums von employ_start und employ_end liegt
total_employ <- total_employ_all %>%
  filter(date.qwt.start >= date.emp.start & date.qwt.start <= date.emp.end)
#do gkv.x and gkv.y have the same values?
sum(total_employ$gkv.x != total_employ$gkv.y) #0 -> gkv.x and gkv.y have the same values, delete gkv.y and rename gkv.x to gkv
total_employ <- total_employ %>% 
  select(-gkv.y) %>%
  rename(gkv = gkv.x)

nrow(total_employ) - nrow(total_stamm) 
#after the filter, there are 42 rows less than before
missing_rows <- total_stamm %>%
  anti_join(total_employ, by = c("pragmaid", "date.qwt.start", "date.qwt.end")) #für 42 Zeilen gibt es keine employment Daten (-> Lücken in den Daten, siehe unten), diese werden exkludiert (aktiver Versichertenstatus ist Inklusionskriterium)

total_employ$emp.type <- as.factor(total_employ$emp.type)
total_employ$sex <- as.factor(total_employ$sex)
total_employ$nationality <- as.factor(total_employ$nationality)
total_employ$ward <- as.factor(total_employ$ward)
total_employ$source <- as.factor(total_employ$source)

```
### Einschub: Sind fehlende Daten für Employment auf Unterbrechungen in Versichertenzeiten zurückzuführen?
```{r check_missing_employment}
#check if missing employment data is due to interruptions in insured periods
check_missing <- left_join(missing_rows, insurance_periods, by = c("pragmaid")) %>%
  select(pragmaid, date.qwt.start, date.qwt.end, date.ins.start, date.ins.end, gkv.x, gkv.y) 

sum(check_missing$gkv.x != check_missing$gkv.y) #0 -> gkv.x and gkv.y have the same values

#filter cases where the inpat treatment is covered by insurance
cases_with_valid_ins <- check_missing %>% filter(date.qwt.start >= date.ins.start & date.qwt.start <= date.ins.end) #there are 8 cases that do have insurance data for the inpatient treatment, but have no corresponding employment data. these cases should be kept in the inpat_employ dataset, as they are insured during the inpatient treatment and the employment status should be set to NA.

# -> some, but not all cases with missing employment data are due to interruptions in insured periods

#add cases with valid insurance to inpat_employ
total_employ <- bind_rows(total_employ, total_stamm %>% filter(pragmaid %in% cases_with_valid_ins$pragmaid & date.qwt.start %in% cases_with_valid_ins$date.qwt.start & date.qwt.end %in% cases_with_valid_ins$date.qwt.end))

table(total_employ$emp.type, useNA = "always") # 8 NAs, so the 8 cases without employment infos, but with insurance are added to the total_employ dataset
``` 
## Hinzufügen von Diagnose-Daten

```{r add_diagnoses}
sum(is.na(all_diagnoses$pragmaid)) #158

table(diagnoses_filtered$icd_type)

# keep only diagnoses of patients with icd_type confirmed, primary, secondary, any and that are not alcohol related
diagnoses_filtered <- all_diagnoses %>% 
  filter(pragmaid %in% total_employ$pragmaid) %>% 
  filter(icd_type %in% c("confirmed", "primary", "secondary", "any")) %>%
  filter(icd.alc == FALSE) %>% #keep only diagnoses that are not alcohol related (as all inpat cases are alcohol related)
  mutate(length_diag = as.integer(difftime(as.Date(date.diag.end), as.Date(date.diag.start), units = "days"))) 

#check
nrow(distinct(total_employ, pragmaid)) - nrow(distinct(diagnoses_filtered, pragmaid)) # 1 patient does not have any diagnoses that matches the criteria
summary(diagnoses_filtered$length_diag)


#plot histogram of length_diag
ggplot(diagnoses_filtered, aes(x = length_diag)) + geom_histogram(binwidth = 1) +
  facet_wrap(~setting, scales = "free_y") +
  scale_x_continuous(limits = c(0, 100))

#show cases with NA in length_diag
diagnoses_filtered %>% 
  filter(is.na(length_diag)) %>%
  select(pragmaid, icd, icd_type, setting, date.diag.start, date.diag.end)

#delete length_diag
diagnoses_filtered <- select(diagnoses_filtered, -length_diag)

sum(is.na(diagnoses_filtered$date.diag.start)) #19
sum(is.na(diagnoses_filtered$date.diag.end)) #8
sum(is.na(diagnoses_filtered$setting)) #0

#if date.diag.end is NA, set it to date.diag.start
diagnoses_filtered <- diagnoses_filtered %>% 
  mutate(date.diag.start = dplyr::if_else(is.na(date.diag.start), date.diag.end, date.diag.start))


diagnoses_employ_alltimes <- left_join(total_employ, diagnoses_filtered, by = c("pragmaid")) 

nrow(distinct(diagnoses_employ_alltimes, pragmaid, qwt_id)) #3823 -> okay

# keep only diagnoses in the timeframe of interest (maximum 2 quarters before treatment start)
diagnoses_employ_fil <- diagnoses_employ_alltimes %>%
  filter(
    #Ambulante Diagnosen (Dauer: 1 Quartal) dürfen nicht später zurückliegend als 2 Quartale vor QWT-Start gestellt worden sein und maximal gleich QWT-Start liegen
     date.diag.start >= (date.qwt.start - days(180)) & date.diag.start <= date.qwt.start)
#Arbeitsdefinition, für stationäre Diagnosen (bzw. alle anderen settings) muss Eingrenzung noch angepasst werden

# GKV X and Y are the same, delete Y and rename X to gkv
sum(diagnoses_employ_fil$gkv.x != diagnoses_employ_fil$gkv.y) 

diagnoses_employ_fil <- diagnoses_employ_fil %>% 
  select(-gkv.y) %>%
  rename(gkv = gkv.x)

#checks
nrow(distinct(diagnoses_employ_fil, pragmaid, qwt_id)) # 3802 (before: 3823 -> 21 cases are filtered out as they did not have a diagnosis in the timeframe of interest - they will be added in the end again

# Charlson and Elixhauser Comorbidity Index

diagnoses_employ_fil$id_pragma_qwt <- paste(diagnoses_employ_fil$pragmaid, diagnoses_employ_fil$qwt_id, sep = "_")

comorb_elix <- comorbidity::comorbidity(x=diagnoses_employ_fil, id = "id_pragma_qwt",
                                code = "icd",map="elixhauser_icd10_quan",
                                assign0 = T,tidy.codes = T)

comorb_char <- comorbidity::comorbidity(x=diagnoses_employ_fil, id = "id_pragma_qwt",
                                code = "icd",map="charlson_icd10_quan",
                                assign0 = T,tidy.codes = T)

comorb_elix_sum <- comorb_elix %>%
  #new column with row sums using all columns except the first one and "alcohol"
  mutate(elix_sum = rowSums(select(., -id_pragma_qwt))) %>%
  select(id_pragma_qwt, elix_sum)

comorb_char_sum <- comorb_char %>%
  #new column with row sums using all columns except the first one and "alcohol"
  mutate(char_sum = rowSums(select(., -id_pragma_qwt))) %>%
  select(id_pragma_qwt, char_sum)

#bind both comorbidity dataframes
comorb_sum <- left_join(comorb_elix_sum, comorb_char_sum, by = "id_pragma_qwt")
      

nrow(distinct(total_employ, pragmaid, qwt_id)) - nrow(distinct(comorb_sum, id_pragma_qwt))
# 21 cases, these have to be added to the comorb_sum dataset

total_employ$id_pragma_qwt <- paste(total_employ$pragmaid, total_employ$qwt_id, sep = "_")

diagnoses_employ <- left_join(total_employ, comorb_sum, by = "id_pragma_qwt")

#are there missings? 
nrow(total_employ) - nrow(diagnoses_employ) #0
sum(is.na(diagnoses_employ$elix_sum)) #21 missings in n_diagnoses_woa
sum(is.na(diagnoses_employ$char_sum)) #21 missings in n_diagnoses_wa

#set NAs to 0
diagnoses_employ <- diagnoses_employ %>% 
  mutate(elix_sum = replace_na(elix_sum, 0),
         char_sum = replace_na(char_sum, 0))

```

### Diagnose Daten Descriptives 

```{r check_ndiagnoses}
#plot histogram of number of diagnoses
ggplot(diagnoses_employ, aes(x = elix_sum)) + geom_histogram(binwidth = 1)
summary(diagnoses_employ$elix_sum)
ggplot(diagnoses_employ, aes(x = char_sum)) + geom_histogram(binwidth = 1)
summary(diagnoses_employ$char_sum) 
```
# Hinzufügen von Pflegegraden
```{r add_pflegegrad}
str(fosterage)
table(fosterage$fost.degree, useNA = "always")
# sowohl Pflegegrade (PG) als auch Pflegestufen (PS). Pflegegrade sind ab 2017 gültig, Pflegestufen bis 2016. Wie Pflegestufen in Pflegegrade umrechnen?
min(qwt$date.qwt.start) #2015-12-11

unique(qwt$date.qwt.start) %>% sort() #5 QWTs wurden vor 2016 begonnen

#Quelle: https://www.gkv-spitzenverband.de/media/dokumente/service_1/Pflegebegutachtung_2017_von_Pflegestufen_zu_Pflegegraden.pdf
# ohne PEA funktioniert Umrechnung nicht eindeutig. Daher wird die Variable zu Pflegebedarf vorhanden/nicht vorhanden kodiert

#conversion_table_PSPG <- c("PS0" = "PG2",
#                      "PS1" = "PG2",
#                      "PS2" = "PG3",
#                      "PS3" = "PG4",
#                      "PSH" = "PG5")

#fosterage <- fosterage %>% 
#  mutate(fost.degree = recode(fost.degree, !!!conversion_table))

fost_qwt <- fosterage %>% 
  filter(pragmaid %in% diagnoses_employ$pragmaid)

#checks
sum(is.na(fost_qwt$date.fost.start)) #0
sum(is.na(fost_qwt$pragmaid)) #0
nrow(distinct(diagnoses_employ, pragmaid)) - nrow(distinct(fost_qwt, pragmaid))
#1663 patients do not have fosterage data
#248 patients have fosterage data


fost_diagnoses_employ_alltimes <- left_join(diagnoses_employ, fost_qwt, by = "pragmaid") 


fost_diagnoses_employ_fil <- fost_diagnoses_employ_alltimes %>%
  filter((date.qwt.start >= date.fost.start & is.na(date.fost.end)) | (date.qwt.start >= date.fost.start & date.qwt.start <= date.fost.end))

nrow(distinct(fost_diagnoses_employ_fil, pragmaid)) #98 patients do have fosterage data that is within the QWT period

# GKV X - GKV Y
sum(fost_diagnoses_employ_fil $gkv.x != fost_diagnoses_employ_fil $gkv.y) #0 -> gkv.x and gkv.y are the same, delete gkv.y and rename gkv.x to gkv
fost_diagnoses_employ_fil  <- fost_diagnoses_employ_fil  %>% 
  select(-gkv.y) %>%
  rename(gkv = gkv.x)

# check data that is filtered out
#check_missing_fost <- total_fost_all %>% 
#  anti_join(fost_diagnoses_employ_fil , by = c("pragmaid", "date.qwt.start", "date.qwt.end", "date.fost.start", "date.fost.end")) %>%
#  select(pragmaid, date.qwt.start, date.qwt.end, date.fost.start, date.fost.end, fost.degree) # -> okay


# add fost_diagnoses_employ_fil  to diagnoses_employ and set fosterage to NA if no fosterage data is available
fost_diagnoses_employ <- diagnoses_employ %>%
  left_join(fost_diagnoses_employ_fil  %>% select(id_pragma_qwt, fost.degree), by = "id_pragma_qwt") %>%
  mutate(fost.degree_bin = as.factor(ifelse(is.na(fost.degree), "nein", "ja")))


table(fost_diagnoses_employ$fost.degree, useNA = "always")
table(fost_diagnoses_employ$fost.degree_bin, useNA = "always")

```

## Hinzufügen von Medikation

```{r add_medication}

med_qwt <- medications %>% 
  filter(pragmaid %in% fost_diagnoses_employ$pragmaid)

#checks
sum(is.na(med_qwt$date.medi.disp)) #0
sum(is.na(med_qwt$pragmaid)) #0
nrow(distinct(fost_diagnoses_employ, pragmaid)) - nrow(distinct(med_qwt, pragmaid)) #45 patients do not have medication data, 1866 have

#add med_qwt to fost_diagnoses_employ
final_data_alltimes <- left_join(fost_diagnoses_employ, med_qwt, by = "pragmaid")
nrow(distinct(med_fost_diagnoses_employ_alltimes, pragmaid)) #1911 patients -> okay

med_fost_diagnoses_employ_fil <- med_fost_diagnoses_employ_alltimes %>%
# only keep medication data that happend during the 3 months before the QWT
  filter(date.medi.disp >= (date.qwt.start - days(30)) & date.medi.disp <= date.qwt.start) %>%
  filter(ATC != "")

nrow(distinct(med_fost_diagnoses_employ_fil, pragmaid, qwt_id)) # 1484 treatments have medication data in the timeframe of interest

#GKV X - GKV Y
sum(med_fost_diagnoses_employ_fil$gkv.x != med_fost_diagnoses_employ_fil$gkv.y) #0 -> gkv.x and 
#gkv.y are the same, delete gkv.y and rename gkv.x to gkv
med_fost_diagnoses_employ_fil <- med_fost_diagnoses_employ_fil %>% 
  select(-c(gkv.y, REZ_ID, LANR_FAGS, date.medi.presc, PZN_ANZ, DDD1000_PK)) %>%
  rename(gkv = gkv.x) %>%
  ungroup()

#missing_med <- total_med_all %>% 
#  anti_join(med_fost_diagnoses_employ_fil, by = c("pragmaid", "date.qwt.start", "date.qwt.end", "date.medi.disp")) %>%
#  select(pragmaid, date.qwt.start, date.qwt.end, date.medi.disp) # -> okay
#rm(missing_med)

#new variable with level 2 ATCs (therapeutische Untergruppe)
med_fost_diagnoses_employ_fil <- med_fost_diagnoses_employ_fil %>%
  group_by(id_pragma_qwt) %>%
  mutate(Level2_ATC = substr(ATC, 1, 3)) %>%
  ungroup()

#how many different values of Level2_ATC are there? 
unique_level2_ATCs <- unique(med_fost_diagnoses_employ_fil$Level2_ATC)
length(unique_level2_ATCs) #64

# welche Untergruppe ist am häufigsten vertreten?
sorted_atc_counts <- med_fost_diagnoses_employ_fil %>%
  count(Level2_ATC, sort = TRUE) #Psycholeptika (N05) kommt am häufigsten vor

#calculate sum of disting full ATC and level 2 ATC codes
med_fost_diagnoses_employ_fil <- med_fost_diagnoses_employ_fil %>%
  group_by(id_pragma_qwt) %>%
  dplyr::summarize(ndistinctATClevel2 = n_distinct(Level2_ATC), 
            ndistinctATC = n_distinct(ATC)) %>%
  ungroup()

table(med_fost_diagnoses_employ_fil$ndistinctATClevel2)

med_fost_diagnoses_employ <- left_join(fost_diagnoses_employ, med_fost_diagnoses_employ_fil, by = "id_pragma_qwt")

#set NAs in ndistinct to 0
med_fost_diagnoses_employ <- med_fost_diagnoses_employ %>%
  mutate(ndistinctATC = ifelse(is.na(ndistinctATC), 0, ndistinctATC)) %>%
  mutate(ndistinctATClevel2 = ifelse(is.na(ndistinctATClevel2), 0, ndistinctATClevel2)) %>%
  mutate(polymedi = as.factor(ifelse(ndistinctATC >= 6, "ja", "nein"))) %>%
  mutate(polymedi_level2 = as.factor(ifelse(ndistinctATClevel2 >= 5, "ja", "nein")))

summary(med_fost_diagnoses_employ$ndistinctATC)
hist(med_fost_diagnoses_employ$ndistinctATC)

summary(med_fost_diagnoses_employ$ndistinctATClevel2)
hist(med_fost_diagnoses_employ$ndistinctATClevel2)

table(med_fost_diagnoses_employ$polymedi)
table(med_fost_diagnoses_employ$polymedi_level2)
```

# Auswahl relevanter Variablen
```{r select_vars}
final_data <- med_fost_diagnoses_employ %>% 
  select(-c(KH_FALL_ID, date.kkh.start, date.kkh.end, date.qwt.start, date.qwt.end, date.emp.start, date.emp.end, id_pragma_qwt, fost.degree, source, icd.primary, icd.secondary, icd.admission, icd.other, died, date.death, ward))
```

# Speicherplatz freigeben
```{r save_data}
#alle Datenfiles die "all" oder "check" oder "missing" im Namen haben, können gelöscht werden
#identifiziere alle Objekte, die gelöscht werden können
objects <- ls()
objects <- objects[grepl("all|check|missing", objects)]
#lösche alle Objekte
rm(list = objects)
#free unused memory
gc()
```

# Überpfrüfung der Daten vor Modellierung
```{r check_data}
final_data$gkv <- as.factor(final_data$gkv)
final_data$pragmaid <- as.factor(final_data$pragmaid)
final_data$sex <- as.factor(final_data$sex)
final_data$nationality <- as.factor(final_data$nationality)

#check for missings
summary(final_data) #8 NAs in EmpType -> set to "other"
final_data$gkv <- as.factor(final_data$gkv)
final_data$emp.type[is.na(final_data$emp.type)] <- "other"

##outliers?
## remove #all outliers that match the definition: bigger than 75% quantile + 3*IQR (Tukey's fences)

# qwt_id
boxplot(final_data$qwt_id) # some patients did a lot of QWTs -> remove
cutoff_qwtid <- quantile(final_data$qwt_id, 0.75) + 3*IQR(final_data$qwt_id) #9 QWTs
cutoff_qwtid
#remove them
final_data <- final_data %>% filter(qwt_id <= cutoff_qwtid)

# ndays
boxplot(final_data$n_days) # no outliers
cutoff_ndays <- quantile(final_data$n_days, 0.75) + 3*IQR(final_data$n_days)
#how many cases are above the cutoff?
sum(final_data$n_days > cutoff_ndays) # 0 cases 

#age
boxplot(final_data$age) # some outliers
cutoff_age <- quantile(final_data$age, 0.75) + 3*IQR(final_data$age)
cutoff_age #103
sum(final_data$age > cutoff_age) # 0 cases


# char_sum
boxplot(final_data$char_sum) # some outliers
cutoff_char <- quantile(final_data$char_sum, 0.75) + 3*IQR(final_data$char_sum)
cutoff_char
final_data <- final_data %>% filter(char_sum <= cutoff_char)

#elix_sum
boxplot(final_data$elix_sum) # some outliers
cuttoff_elix <- quantile(final_data$elix_sum, 0.75) + 3*IQR(final_data$elix_sum)
cuttoff_elix
final_data <- final_data %>% filter(elix_sum <= cuttoff_elix)

#ndistinctATClevel2
boxplot(final_data$ndistinctATClevel2) # some outliers
cutoff_ndistinctATClevel2 <- quantile(final_data$ndistinctATClevel2, 0.75) + 3*IQR(final_data$ndistinctATClevel2)
cutoff_ndistinctATClevel2
final_data <- final_data %>% filter(ndistinctATClevel2 <= cutoff_ndistinctATClevel2)


# check for multicollinearity
#Just run “linear regression” after assuming categorical dependent variable as continuous variable
final_data$treat_dur_cat_num <- as.numeric(final_data$treat_dur_cat)
vif_model <- lm(treat_dur_cat_num ~ sex + age + qwt_id + nationality + emp.type + elix_sum + fost.degree_bin + ndistinctATClevel2, data = final_data)

car::vif(vif_model) #no multicollinearity
#"A consequence is that when using adjusted adjusted generalized standard error inflation factor (GSIF = GVIF^(1/(2*Df)), we must take the square-root of our rules of thumb for what is a large value – aGSIF values above √2.5 (1.6) may be of concern, and values above √5 or √10 (2.2 or 3.2) are indicative of a more serious problem"

```

#Multinomiale Modelle

```{r multinom_models}

# Initialisiere einen leeren DataFrame für die Modellanpassungsparameter
model_summaries <- data.frame(
  Model = character(),
  Deviance = numeric(),
  AIC = numeric(),
  BIC = numeric(),
  stringsAsFactors = FALSE
)

add_model_summary <- function(model, model_name) {
  summary <- getSummary.mblogit(model)
  stats <- summary$sumstat
  model_summaries <<- rbind(model_summaries, data.frame(
    Model = model_name,
    Deviance = stats["deviance"],
    AIC = stats["AIC"],
    BIC = stats["BIC"]
  ))
}

#nur Intercept und random effects
model1 <- mblogit(formula = treat_dur_cat ~ 1, random = ~ 1 | pragmaid, data = final_data)
getSummary.mblogit(model1)
add_model_summary(model1, "Intercept")

model2 <- mblogit(formula = treat_dur_cat ~ sex, random = ~ 1 | pragmaid, data = final_data) #model 2 führt zu Verbesserungen in deviance und AIC, aber nicht in BIC. Außerdem ist sex ein signifikanter Prädiktor
getSummary.mblogit(model2)
add_model_summary(model2, "Model 2")


model3 <- mblogit(formula = treat_dur_cat ~ sex + age, random = ~ 1 | pragmaid, data = final_data)
getSummary.mblogit(model3) #Modell 3 hat die besten Anpassungswerte basierend auf Devianz, AIC und BIC. "age" scheint ein signifikanter Prädiktor für die Kategorien „7–20 Tage“ und „21+ Tage“ im Vergleich zu „1-6 Tage“ zu sein.
add_model_summary(model3, "Model 3")

model4 <- mblogit(formula = treat_dur_cat ~ sex + age + qwt_id, random = ~ 1 | pragmaid, data = final_data)
getSummary.mblogit(model4) # Modell 4 hat die besten Anpassungswerte basierend auf Devianz, AIC und BIC. "qwt_id" scheint ein (negativer) signifikanter Prädiktor für die Kategorien „21+ Tage“ im Vergleich zu „1-6 Tage“ zu sein.
add_model_summary(model4, "Model 4")

model5 <- mblogit(formula = treat_dur_cat ~ sex + age + qwt_id + nationality, random = ~ 1 | pragmaid, data = final_data)
getSummary.mblogit(model5) # Modell 5 bietet keinen Vorteil gegenüber Modell 3 (außer leicht niedrigerer deviance), nationality wird nicht in das modell aufgenommen
add_model_summary(model5, "Model 5")

model6 <- mblogit(formula = treat_dur_cat ~ sex + age + qwt_id + emp.type, random = ~ 1 | pragmaid, data = final_data)
getSummary.mblogit(model6) # Model 6 hat besseres AIC und deviance als Modell 4, aber schlechteres BIC- emp type ist signifikanter Prädiktor
add_model_summary(model6, "Model 6")

model7 <- mblogit(formula = treat_dur_cat ~ sex + age + qwt_id + emp.type + gkv, random = ~ 1 | pragmaid, data = final_data) # Model 7 bietet keinen Vorteil gegenüber Modell 6, gkv wird daher nicht ins Model aufgenommen
getSummary.mblogit(model7)
add_model_summary(model7, "Model 7")

model8 <- mblogit(formula = treat_dur_cat ~ sex + age + qwt_id + emp.type + elix_sum, random = ~ 1 | pragmaid, data = final_data)
getSummary.mblogit(model8) 
add_model_summary(model8, "Model 8") # Hinzufügen von elix_sum bietet keinen Vorteil im Modelfit


# ist char_sum ein besserer Prädiktor?
model9 <- mblogit(formula = treat_dur_cat ~ sex + age + qwt_id + emp.type + char_sum, random = ~ 1 | pragmaid, data = final_data)
getSummary.mblogit(model9)
add_model_summary(model9, "Model 9") # char_sum verbessert den Modelfit und ist ein signifiukanter Prädiktor. Wieso ist char_sum besser als elix_sum?

model10 <- mblogit(formula = treat_dur_cat ~ sex + age + qwt_id + emp.type + char_sum + fost.degree_bin, random = ~ 1 | pragmaid, data = final_data)
getSummary.mblogit(model10)
add_model_summary(model10, "Model 10") # keine Verbesserung durch hinzufügen von fost.degree_bin

model11 <- mblogit(formula = treat_dur_cat ~ sex + age + qwt_id + emp.type + char_sum + ndistinctATClevel2, random = ~ 1 | pragmaid, data = final_data)
getSummary.mblogit(model11)
add_model_summary(model11, "Model 11") # keine Verbesserung gegenüber Modell 9 (außer in deviance)

#find the best fitting model
choose_best_model <- function(summary_df, criterion) {
  if (!criterion %in% names(summary_df)) {
    stop("Ungültiges Kriterium. Wähle entweder 'Deviance', 'AIC' oder 'BIC'.")
  }
  best_model_row <- summary_df[which.min(summary_df[[criterion]]), ]
  return(best_model_row)
}

choose_best_model(model_summaries, "BIC") #Model 4
choose_best_model(model_summaries, "AIC") #Model 9 
choose_best_model(model_summaries, "Deviance") #Model 11 

sjPlot::plot_model(model9)

```
# Predicted Probabilities 

```{r plot_pred_probs}
# Predicted probabilities
# Erstelle ein neues Datenset, durch das die Variablen, die dich interessieren, variiert werden


#define function to generate new data that varies the variables of interest (age, qwt_id, char_sum) and then plot the predicted probabilities with the variable of interest on x axis

predict_and_plot <- function(variable_of_interest, model, data) {
  # Werte für jede Variable von Interesse
  age_values <- seq(from = min(data$age,na.rm=TRUE),to=max(data$age, na.rm = TRUE), length.out = 10)  # 10 Werte für Alter
  qwt_id_values <- seq(from = min(data$qwt_id,na.rm=TRUE),to=max(data$qwt_id, na.rm = TRUE), length.out = 9)  # 4 Werte für qwt_id
  char_sum_values <- seq(from = min(data$char_sum,na.rm=TRUE),to=max(data$char_sum, na.rm = TRUE), length.out = 5)  # 4 Werte für char_sum  # Neue Daten je nach Variable von Interesse erstellen
  if (variable_of_interest == "age") {
    new_data <- expand.grid(
      age = age_values,
      sex = unique(data$sex),
      emp.type=unique(data$emp.type),
      qwt_id = mean(data$qwt_id, na.rm=TRUE),
      char_sum=mean(data$char_sum, na.rm = TRUE)
    )
    x_label <- "Alter"
  } else if (variable_of_interest == "qwt_id") {
    new_data <- expand.grid(
      age = mean(data$age, na.rm=TRUE),
      sex = unique(data$sex),
      emp.type=unique(data$emp.type),
      qwt_id = qwt_id_values,
      char_sum=mean(data$char_sum, na.rm = TRUE)
    )
    x_label <- "QWT ID"
  } else if (variable_of_interest == "char_sum") {
    new_data <- expand.grid(
      age = mean(data$age, na.rm=TRUE),
      sex = unique(data$sex),
      emp.type=unique(data$emp.type),
      qwt_id = mean(data$qwt_id, na.rm=TRUE),
      char_sum= char_sum_values
    )
    x_label <- "Charlson Sumscore"
  } else {
    stop("Ununterstützte Variable der Interesse.")
  }
  
  # Dummy-Level für pragmaid hinzufügen, falls notwendig
  if ("pragmaid" %in% colnames(data)) {
    new_data$pragmaid <- levels(data$pragmaid)[1] # Nutze ein existierendes Level als Dummy
  }
  
  # Vorhersagen berechnen
  predicted_probs <- predict(model, newdata = new_data, type = "response")
  
  # Kombiniere die Vorhersagen mit den Eingabewerten
  predicted_data <- cbind(new_data, predicted_probs)
  
  # Reshape die Daten für ggplot
  predicted_long <- pivot_longer(predicted_data, 
                                 cols = c("1-6 Tage", "7-20 Tage", "21+ Tage"), 
                                 names_to = "treat_dur_cat", 
                                 values_to = "predicted_prob")
  
  #change the order of the levels of treat_dur_cat
  predicted_long$treat_dur_cat <- factor(predicted_long$treat_dur_cat, levels = c("1-6 Tage", "7-20 Tage", "21+ Tage"))
  
  # Plotten der vorhergesagten Wahrscheinlichkeiten
  ggplot(predicted_long, aes(x = .data[[variable_of_interest]], y = predicted_prob, color = sex)) +
    geom_line() +
    facet_grid(treat_dur_cat ~ emp.type, scales = "free") +
    xlab(x_label) +
    ylab("Vorhergesagte Wahrscheinlichkeit") +
    theme_minimal() +
    labs(color = "Geschlecht") +
    theme(legend.position = "bottom")
}


predict_and_plot("qwt_id", model9, final_data)
predict_and_plot("age", model9, final_data)
predict_and_plot("char_sum", model9, final_data)

#save plots in folder_plot
ggsave(file.path(folder_plot, "predicted_probs_qwt.png"), predict_and_plot("qwt_id", model9, final_data), width = 20, height = 25, units = "cm")
ggsave(file.path(folder_plot, "predicted_probs_age.png"), predict_and_plot("age", model9, final_data), width = 20, height = 25, units = "cm")
ggsave(file.path(folder_plot, "predicted_probs_char.png"), predict_and_plot("char_sum", model9, final_data), width = 20, height = 25, units = "cm")



```
# Interpretation der festen Effekte (Refernzgruppe 1-6 Tage)

## Signifikanz und Modellkoeffizienten

- 1.39 (Intercept) ist geschätzt als log odds für eine Behandlungsdauer von 7-20 Tagen bei einer Frau, die 0 Jahre alt ist und ihre 0. QWT hat -> Log Odds positiv -> Behandlungen von 7-20 Tagen sind wahrscheinlicher als 1-6 Tage

- signifikant negativer Koeffizienten für Geschlecht:männlich -> Männer haben eine geringere Wahrscheinlichkeit für Behandlungen von 21+ Tagen als Frauen (7-20 Tage n.s.)

- signifikant positiver Koeffizienten für Alter -> mit steigendem Alter steigt die Wahrscheinlichkeit für Behandlungen von 7-20 Tagen im Vergleich zu 1-6 Tagen (21+ Tage n.s.)

- signifikant negativer Koeffizient für QWT_ID -> mit fortlaufender QWT_ID sinkt die Wahrscheinlichkeit für Behandlungen 21+ Tagen (7-20 Tage n.s.)

- Menschen in Beschäfigung haben verglichen mit allen anderen Beschäftigungsarten eine höhere Wahrscheinlichkeit für Behandlungen von 7-20 Tagen und 21+ Tagen im Vergleich zu 1-6 Tagen

- signifikant positiver Koeffizient für Charlson Sumscore -> mit steigendem Charlson Sumscore steigt die Wahrscheinlichkeit für Behandlungen von 7-20 Tagen und 21+ Tagen im Vergleich zu 1-6 Tagen


Der zufällige Intercept auf Gruppenebene (pragmaid) ist sehr gering, was darauf hindeutet, dass die Gruppierungsvariable pragmaid einen sehr kleinen Einfluss auf die Variation der Behandlungsdauer hat.


## Predicted Probabilities

- mit steigendem Charlson Sumsore steigt die Wahrscheinlichkeit für eine längere Behandlungsdauer (7-20 Tage und 21+ Tage), während die Wahrscheinlichkeit für eine kürzere Behandlungsdauer (1-6 Tage) abnimmt. Dies ist konsistent über Beschäftigungsstatus hinweg und bei beiden Geschlechtern zu beobachten.

- Männer haben eine geringere Wahrscheinlichkeit für eine längere Behandlungsdauer (21+ Tage) im Vergleich zu Frauen

- Menschen in Beschäftigung haben eine geringere Wahrscheinlichkeit für kürzere Behandlungsdauern (1-6 Tage) 








# Check linearity assumption
```{r check_linearity}

# ASSUMPTIONS:
#Linearity: Linear relationship between continuous variables and the logit transformation of the outcome variable. 

probabilities <- predict(model9, type = "response")
#dataset with only continuous variables
final_data_cont <- final_data %>% ungroup() %>% select_if(is.numeric) %>% select(-(c(treat_dur_cat_num, n_days, ndistinctATC, elix_sum, yob)))

predictors <- colnames(final_data_cont)


# Logit für jede Kategorie berechnen 
logits <- apply(probabilities, 2, function(p) log(p / (1 - p)))

logits_df <- as.data.frame(logits) 
combined_data <- cbind(final_data_cont, logits_df)

final_data_long <- combined_data %>%
  pivot_longer(
    cols = all_of(names(logits_df)),  # Nutze die Spaltennamen deiner logits_df direkt
    names_to = "category",
    values_to = "logit"
  ) %>%
  pivot_longer(
    cols = all_of(predictors),   # Stelle sicher, dass predictors existiert
    names_to = "predictors",
    values_to = "predictor.value"
  )

# Scatterplot
ckeck_lin <- ggplot(final_data_long, aes(x = predictor.value, y = logit)) +
  geom_point(size = 0.5, alpha = 0.5) +
  geom_smooth(method = "loess") +
  theme_bw() +
  facet_grid(category ~ predictors, scales = "free") +
  labs(
    title = "Beziehung zwischen Prädiktoren und Logits",
    x = "Prädiktorwert",
    y = "Logit"
  ) +
    theme(
    strip.text = element_text(size = 6)  # Verkleinert die Textgröße für Facettenbeschriftungen
  )

ggsave("check_linearity_qwt.png", ckeck_lin, width = 20, height = 25, units = "cm")

#looks mostly fine, but maybe some problems with age (plot for 21+ days), looks rather cubic than linear (only in extreme ends)
```



# ALT!

```{r old_code}
qwt <- qwt %>% 
  filter(ENTL301 != "Tod") %>%
  mutate(unpl_drop = factor(case_when(
  ENTL301 %in% c("aus sonstigen Gründen beendet", "gegen ärztlichen Rat beendet", "gegen ärztlichen Rat beendet, nachstat. Beh. vorgeseh.") ~ 1,
  ENTL301 %in% c("regulär", "beendet, nachstat. Beh. vorgesehen", "Verlegung in ein anderes Krankenhaus", "Rehaeinrichtung", "Pflegeeinrichtung",
                 "externe Verlegung zur psychiatrischen Behandlung", "aus sonst. Gründen beend., nachstat. Beh. Vorges.", "interne Verlegung m. Wechsel zw. D. Gelt.b. BPflV u. KHEntgG", "Fallabschl. (int. V.) b. Wechsel zw. Voll- und teilst. Beh.") ~ 0,
  TRUE ~ NA_real_), levels = c(0, 1), labels = c("nein", "ja")))

prop.table(table(qwt$unpl_drop))
ggplot(qwt, aes(x = unpl_drop, y = n_days)) + geom_violin() + geom_boxplot(width = 0.1) + theme(axis.text.x = element_text(angle = 35, hjust = 1))


# Hinzufügen der OPS Codes

#
#show rows that have the same KH_FALL_ID
#qwt_duplicates <- qwt %>% 
#  group_by(KH_FALL_ID, pragmaid) %>% 
#  filter(n() > 1) #es gibt einige Personen, die innerhalb eines KH Aufenthalts mehrere Rehas gemacht haben

#rename ops.date to date.qwt.start
#qwt_OPS <- qwt_OPS %>% 
#  filter(grepl("^8-985|^8985|^9-647|^9647", OPS)) %>%
#  rename(date.qwt.start = date.ops) %>%
#  mutate(date.qwt.start = as.Date(date.qwt.start))

#qwt_full <- left_join(qwt, qwt_OPS, by = c("KH_FALL_ID", "pragmaid", "gkv", "date.qwt.start"))



#add diagnoses to total_employ and filter for diagnoses according to time criteria and exclude alcohol diagnoses
#diagnoses_employ_all <- left_join(total_employ, diagnoses_filtered, by = c("pragmaid", "gkv")) %>%
#  filter(
#    (date.diag.start <= date.qwt.start & date.diag.end >= (date.qwt.end - months(1))) |  # Diagnosestart muss vor oder gleich QWT-Start liegen und Diagnose muss noch bis mindestens 1 Monat vor QWT-Ende laufen
#    (is.na(date.diag.end) & date.diag.start >= (date.qwt.start - months(1)) & date.diag.start <= #date.qwt.start) |  # Falls date.diag.end NA ist, darf date.diag.start nur bis zu einem Monat vor QWT-Start und maximal gleich QWT-Start liegen
#    (is.na(date.diag.start) & date.diag.end >= (date.qwt.end - months(1)) & date.diag.end <= (date.qwt.end + weeks(1)))  # Falls date.diag.start NA ist, darf date.diag.end nur bis zu einem Monat vor und eine Woche nach QWT-Ende liegen
#  ) %>%
#  filter(icd.alc == "FALSE") %>%
#  distinct(pragmaid, qwt_id, icd, .keep_all = TRUE)

#----------------------------------------------
# Testen mit einem kleinen Beispiel-Datensatz
test_df <- data.frame(
  pragmaid = 1:6,
  gkv = c("aok", "aok", "dak", "dak", "dak", "aok"),
  date.qwt.start = as.Date(c('2021-01-01', '2021-06-01', '2021-07-01', '2021-10-01', '2022-01-01', '2022-04-01')),
  setting = c("outpatient", "inpatient", "outpatient", "inpatient", "outpatient", "outpatient"),
  date.diag.start = as.Date(c('2019-07-01', '2020-11-01', '2021-03-01', '2021-09-01', '2021-11-01', '2022-01-01')),
  qwt_id = 1:6,
  icd = c("A", "B", "C", "D", "E", "F")
)

result <- test_df %>%
  mutate(test_column = case_when(
    (setting == "outpatient" & date.diag.start >= (date.qwt.start - months(6)) & date.diag.start <= date.qwt.start) |
    (setting != "outpatient" & date.diag.start >= (date.qwt.start - months(6)) & date.diag.start <= date.qwt.start) ~ 1,
    TRUE ~ 0
  ))
#----------------------------------------------


#Plausi check ndistinct ATC (should increase with elix_sum)
ggplot(final_data, aes(x = elix_sum, y = ndistinctATC)) + geom_point() + geom_smooth(method = "lm")
#correlation between elix_sum and ndistinctATC?
cor(final_data$elix_sum, final_data$ndistinctATC) #0.50

#correlation of elix_sum and char_sum
cor(final_data$elix_sum, final_data$char_sum) #0.75-> high correlation
ggplot(final_data, aes(x = elix_sum, y = char_sum)) + geom_point() + geom_smooth(method = "lm")

#correlation between elix_sum and ndistinctATClevel2
ggplot(final_data, aes(x = elix_sum, y = ndistinctATClevel2)) + geom_point() + geom_smooth(method = "lm")
cor(final_data$elix_sum, final_data$ndistinctATClevel2) #0.51

#corr between char_sum and ndistinctATClevel2
cor(final_data$char_sum, final_data$ndistinctATClevel2) #0.35
ggplot(final_data, aes(x = char_sum, y = ndistinctATClevel2)) + geom_point() + geom_smooth(method = "lm")
```

## Logistisches Modell zur Vorhersage von dichotomisierter Behandlungsdauer (unter vs. über 20 Tage)
```{r model_glmm}

#model1.1 <- glmmTMB(treat_dur_bin ~ sex + age + qwt_id + nationality + emp.type + elix_sum + fost.degree_bin + polymedi + (1|gkv/pragmaid), data = final_data, family = binomial)

#summary(model1.1)
```

## Ordinales Modell zur Vorhersage von Behandlungsdauer in drei Kategorien
```{r model_clmm}
# Modellvergleich mit und ohne GKV
#model1.2 <- clmm(treat_dur_cat ~ sex + age + qwt_id + nationality + emp.type + elix_sum + fost.degree_bin + polymedi + gkv + (1|pragmaid), data = final_data)

#summary(model1.2)
#AIC(model1.2)
#BIC(model1.2)
#logLik(model1.2)

#model1.3 <- clmm(treat_dur_cat ~ sex + age + qwt_id + nationality + emp.type + elix_sum + fost.degree_bin + polymedi + (1|pragmaid), data = final_data)

#print(model1.3)
#summary(model1.3)
#AIC(model1.3)
#BIC(model1.3)
#logLik(model1.3)

#Modell ohne GKV ist besser
```

### Welche Variable für Medikation ergibt das beste Modell?
```{r model_med}
#Modell mit ndistinctATC

#model2.1 <- clmm(treat_dur_cat ~ sex + age + qwt_id + nationality + emp.type + elix_sum + fost.degree_bin + polymedi + (1|pragmaid), data = final_data)

#model2.2 <- clmm(treat_dur_cat ~ sex + age + qwt_id + nationality + emp.type + elix_sum + fost.degree_bin + polymedi_level2 + (1|pragmaid), data = final_data)

#model2.3 <- clmm(treat_dur_cat ~ sex + age + qwt_id + nationality + emp.type + elix_sum + fost.degree_bin + ndistinctATClevel2 + (1|pragmaid), data = final_data)

#model2.4 <- clmm(treat_dur_cat ~ sex + age + qwt_id + nationality + emp.type + elix_sum + fost.degree_bin + ndistinctATC + (1|pragmaid), data = final_data)

#model2.5 <- clmm(treat_dur_cat ~ sex + age + qwt_id + nationality + emp.type + elix_sum + fost.degree_bin + (1|pragmaid), data = final_data)
#plomedikation mitaufzunehmen macht das Modell kaum/gar nicht besser, je nach Kriterium sogar schlechter

#compare models
#for (i in 1:5) {
#  print(paste("Model", i))
#  print(AIC(get(paste("model2.", i, sep = ""))))
#  print(BIC(get(paste("model2.", i, sep = ""))))
#  print(logLik(get(paste("model2.", i, sep = ""))))
#}

#summary(model2.3)
#save(model2.3, file = "modeloutput_CLMM_PRAGMA_dropout.RData")
#summary(model2.5) #elix_sum ist kein signifikanter Prädiktor, egal ob Medikation im Modell ist oder nicht
#[1] "Model 4"
#[1] 7021.353
#[1] 7102.56
#'log Lik.' -3497.677 (df=13)                

#[1] "Model 2"
#[1] 7020.536
#[1] 7101.743 -> erniedrigen auf 5 medi -> schlechterer fit

#Model mit 30 Tage Look Back Window und ndistinctATClevel2 hat das beste AIC, laut BIC (restriktiver gegenüber weiteren Prädiktoren) ist das Modell ohne Medikation am besten





#Modell 3 (treat_dur_cat ~ sex + age + qwt_id) scheint insgesamt die beste Modellanpassung zu bieten, basierend auf AIC und BIC, trotz der geringfügigen Verbesserung der Pseudo-R²-Werte durch Modell 4.
#Modell 4 (treat_dur_cat ~ sex + age + qwt_id + nationality) bietet die besten Pseudo-R²-Werte und die niedrigste Deviance, aber es hat einen leicht höheren AIC und BIC im Vergleich zu Modell 3. Daher wird nationality nicht in das endgültige Modell aufgenommen.
model3.5 <- mblogit(formula = treat_dur_cat ~ sex + age + qwt_id + emp.type, random = ~ 1 | pragmaid, data = final_data)
getSummary.mblogit(model3.5) #Modell 5 erklärt die Daten am umfassendsten und bietet insgesamt die beste Passung, basierend auf AIC, BIC, Pseudo-R² und Deviance. Allerdings hat Modell 3 ein besseres BIC. 
model3.6 <- mblogit(formula = treat_dur_cat ~ sex + age + qwt_id + emp.type + gkv, random = ~ 1 | pragmaid, data = final_data)
getSummary.mblogit(model3.6) #Modell 6 ist besser
model3.7.1 <- mblogit(formula = treat_dur_cat ~ sex + age + qwt_id + emp.type + gkv + elix_sum, random = ~ 1 | pragmaid, data = final_data)
getSummary.mblogit(model3.7.1) #Komorbidität nach Elixhauser verbessert Modell nicht und hat auch keinen siginifikanten Erklärungswert
model3.7.2 <- mblogit(formula = treat_dur_cat ~ sex + age + qwt_id + emp.type + gkv + char_sum, random = ~ 1 | pragmaid, data = final_data)
getSummary.mblogit(model3.7.2) #Komorbidität nach Charlson verbessert Modell und hat siginifikanten Erklärungswert
model3.8 <- mblogit(formula = treat_dur_cat ~ sex + age + qwt_id + emp.type + gkv + char_sum + fost.degree_bin, random = ~ 1 | pragmaid, data = final_data)
getSummary.mblogit(model3.8) #Modell 7.2 ist besser
model3.9 <- mblogit(formula = treat_dur_cat ~ sex + age + qwt_id + emp.type + gkv + char_sum + ndistinctATClevel2, random = ~ 1 | pragmaid, data = final_data)
getSummary.mmblogit(model3.9)#Basierend auf den AIC-, BIC- und Pseudo-R²-Maßen scheint Model 3.9 das beste Modell zu sein. Es hat die niedrigsten AIC- und die besten Pseudo-R²-Werte (McFadden, Cox-Snell und Nagelkerke). Obwohl es nicht den niedrigsten BIC-Wert hat (dieser geht an Model 3.7.2), sind die anderen Verbesserungen signifikant.

# alt: Modell 6 ist besser, interessant ist aber, dass aus den dtrei Prädiktoren, die die Krankheitslast beschreiben (forst_degree, elix_sum, ndistinctATClevel2), ndistinctATClevel2 den besseren model fit bietet nach allen Kriterien zufolge

```