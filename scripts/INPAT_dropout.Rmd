---
title: "INPAT_dropout"
author: "Anna"
date: "2024-08-07"
output: 
  html_document:
    code_folding: hide
---

# To-Dos
- Outlier Removal?
-   ....

Bei INPAT handelt es sich um stationäre, alkoholbezogene Kontakte (Haupt- oder Fachabteilungsdoiagnose Alkohol), die KEIN qualifizierter Entzug sind. OPS Codes: 9-60x; 9-61x; 9-62x

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(warn = -1)
```

# Vorbereitungen

```{r essentials}
# clean workspace
rm(list=ls())
packages <- c("data.table", "tidyverse", "ggplot2", "comorbidity", "car", "glmmTMB", "lme4", "ordinal", "export", "mclogit", "sjPlot", "see", "nnet", "ggeffects", "DHARMa", "effects", "performance")

# Install packages not yet installed
installed_packages <- packages %in% rownames(installed.packages())
if (any(installed_packages == FALSE)) {
  install.packages(packages[!installed_packages])
}
# Load packages
invisible(lapply(packages, library, character.only = TRUE))

# current date:
DATE <- format(Sys.Date(), "%Y%m%d")

# themes and options
options(scipen = 999)

# output folders
folder_table <- file.path("..", "output/tables")
folder_plot <- file.path("..", "output/figures")

if (!file.exists(folder_table)) {
  dir.create(folder_table, recursive = TRUE)
}

if (!file.exists(folder_plot)) {
  dir.create(folder_plot, recursive = TRUE)
}
```

# Daten Import

```{r data_import}
print(getwd())
datapath <- file.path("..", "input") 
#read in all RDS-files in datapath 
filenames <- list.files(datapath, pattern = "\\.rds$", full.names = T)

names <- c("pragma_id_GKV", "all_diagnoses", "medications", "employment", "fosterage", "income", "insurance_periods", "inpat_OPS", "inpat", "qwt_OPS", "qwt", "reha", "reha_new")

if (length(filenames) != length(names)) {
  stop("Die Anzahl der Dateien stimmt nicht mit Anzahl names überein.")
}

#save all files as separate dataframes
ldf <- lapply(filenames, readRDS)
names(ldf) <- names[1:length(ldf)]
print(names(ldf))
list2env(ldf, envir = .GlobalEnv) #save all dataframes in global environment as dataframes
```

# Daten vorbereiten

## Daten Struktur
```{r data_structure}
str(inpat)
inpat$n.days <- as.integer(inpat$n.days)

#convert pragmaid to factor in all dataframes
# harmonise column names
#


ldf <- lapply(names(ldf), function(df_name) {
  df <- ldf[[df_name]]
  
  # pragmaid in Faktor umwandeln, falls vorhanden
  if ("pragmaid" %in% colnames(df)) {
    df <- df %>%
      mutate(pragmaid = as.factor(pragmaid))
  }
  
  if (df_name %in% c("reha_new", "reha", "inpat", "qwt")) {
    
    date_columns <- grep("^date\\.(inpat|qwt|drvreha|reha)\\.(start|end)$", colnames(df), value = TRUE)
    
    # Wenn solche Spalten existieren, benenne sie um
    if (length(date_columns) > 0) {
      # Ersetze "date.[irgendwas]" durch "date.treat"
      new_names <- gsub("^date\\..*\\.", "date.treat.", date_columns)
      df <- df %>%
        rename_with(~ new_names, all_of(date_columns))
      
      treatment_types <- gsub("^date\\.(.*)\\..*$", "\\1", date_columns)  # Extrahiere den Mittelteil
      unique_treatments <- unique(treatment_types)
      print(treatment_types)
      df <- df %>%
        mutate(treatment = factor(unique_treatments[1]))  # Füge die Spalte treatment hinzu
    }
  }
  
  return(df)
})

# Überprüfen der Struktur von ldf, um sicherzustellen, dass die Namen korrekt sind
str(ldf)
names(ldf) <- names[1:length(ldf)]

list2env(ldf, envir = .GlobalEnv)
```

## Check Zeiträume

```{r check_immconsec}

## DIREKTE ANSCHLÜSSE
#wenn sich ein treatment direkt an das vorangehende treatment anschließt, sollen beide zusammengefasst werden

inpat <- inpat %>%
  arrange(pragmaid, date.treat.start) %>%
  group_by(pragmaid) %>%
  mutate(
    direkter_anschluss = (date.treat.start == lag(date.treat.end, default = NULL)) | (date.treat.start == lag(date.treat.end, default = NULL) + 1)) #das Startdatum ist gleich dem Enddatum oder es ist um einen Tag versetzt

table(inpat$direkter_anschluss, useNA = "always") #14 with direkter anschluss

#check -> okay
inpat %>% arrange(pragmaid, date.treat.start) %>% filter(direkter_anschluss | lead(direkter_anschluss)) %>% select(pragmaid, date.treat.start, date.treat.end)
```

## Optional: Direkte Anschlüsse zu einem Treatment zusammenfassen

```{r combine_consectreatments}

inpat <- inpat %>% 
  group_by(pragmaid) %>%
  arrange(date.treat.start) %>%
  mutate(
    date.treat.start = case_when(
      direkter_anschluss ~ lag(date.treat.start),
      TRUE ~ date.treat.start
    )
  ) %>%
  filter(is.na(lead(direkter_anschluss)) | !lead(direkter_anschluss)) %>%  #Behalte nur diejenigen Zeilen, bei denen `direkter_anschluss` des nächsten Datensatzes FALSE ist
  ungroup()
```

## Any OVERLAPS between treatments within pragmaid?

```{r check_overlaps}
inpat$overlap <- FALSE

inpat <- inpat %>%
  group_by(pragmaid) %>%
  mutate(overlap = sapply(1:n(), function(i) {
    any(date.treat.start[i] < date.treat.end[-i] & date.treat.end[i] > date.treat.start[-i])
  }))

table(inpat$overlap, useNA = "always") #45 cases with overlap

overlapping_IDs <- inpat %>% filter(overlap == TRUE) %>% pull(pragmaid) %>% unique()

# Plot erstellen, um Überlappungen zu visualisieren
ggplot(inpat %>% filter(pragmaid %in% overlapping_IDs), 
       aes(y = pragmaid)) +
  geom_segment(aes(x = date.treat.start, 
                   xend = date.treat.end, 
                   yend = pragmaid, 
                   alpha = as.factor(overlap)),
               size = 5) +
  scale_alpha_manual(values = c(`FALSE` = 0.3, `TRUE` = 1)) +
  labs(x = "Date", y = "Pragma ID") +
  theme_minimal() 
```

## Optional: Overlaps in treatments entfernen
```{r remove_overlaps}

cases_to_remove <- inpat %>% 
  filter(overlap == TRUE) %>%
  group_by(pragmaid) %>%
  arrange(pragmaid, date.treat.start) %>%
  mutate(group_overlap = cumsum(
      coalesce(
        as.logical(date.treat.start > lag(date.treat.end, n = 1, default = first(date.treat.start)) &
                   date.treat.start > lag(date.treat.end, n = 2, default = first(date.treat.start)) &
                   date.treat.start > lag(date.treat.end, n = 3, default = first(date.treat.start))
        ), TRUE
      ))) %>%
  group_by(pragmaid, group_overlap) %>%
  mutate(
    max_n_days = max(n.days),  # Maximalwert pro Gruppe berechnen
    keep = case_when(
      n.days == max_n_days & row_number() == which.max(n.days) ~ TRUE,  # Behalte die erste Zeile mit max_n_days
      n.days == max_n_days ~ FALSE,                                   # Andere mit max_n_days auf FALSE setzen
      TRUE ~ FALSE                                                    # Kleinere Werte ebenfalls auf FALSE
    )
  ) 
  
cases_to_remove %>% arrange(pragmaid, date.treat.start) %>% select(pragmaid, date.treat.start, date.treat.end, n.days, ENTL301, overlap, group_overlap, keep, max_n_days)

#!!common columns in cases_to_remove and inpat
common_cols <- intersect(names(cases_to_remove), names(inpat))

sum(cases_to_remove$keep == FALSE)

#inpat: remove cases with keep == "remove" in cases_to_remove
inpat <- inpat %>% 
  left_join(cases_to_remove, by = common_cols) %>%
  filter(is.na(keep) | keep == TRUE) %>%
  select(-c(overlap, group_overlap, keep, direkter_anschluss))

```

## Outcome Variablen Definition?

### ENTLASS301

```{r recode_ENTL}
labels_entl301 <- c(
  "1" = "regulär",
  "2" = "beendet, nachstat. Beh. vorgesehen",
  "3" = "aus sonstigen Gründen beendet",
  "4" = "gegen ärztlichen Rat beendet",
  "6" = "Verlegung in ein anderes Krankenhaus",
  "7" = "Tod",
  "9" = "Rehaeinrichtung",
  "10" = "Pflegeeinrichtung",
  "14" = "aus sonst. Gründen beend., nachstat. Beh. Vorges.",
  "15" = "gegen ärztlichen Rat beendet, nachstat. Beh. vorgeseh.",
  "17" = "interne Verlegung m. Wechsel zw. D. Gelt.b. BPflV u. KHEntgG",
  "22" = "Fallabschl. (int. V.) b. Wechsel zw. Voll- und teilst. Beh."
)

inpat$ENTL301 <- factor(inpat$ENTL301, levels = names(labels_entl301), labels = labels_entl301)
table(inpat$ENTL301, useNA = "always")
#Einteilung der ENTLASS Gründe in "ungeplant abgebrochen" vs "regulär beendet bzw. nicht ungeplant abgebrochen" (wenig sensitiv, aber spezifisch, dh wahrscheinlich werden viele Fälle verpasst, die ungeplant abgebrochen haben, aber dafür wenig falsch positive, dh hohe spezifität)
inpat <- inpat %>% 
  filter(ENTL301 != "Tod") %>%
  mutate(unpl_drop = factor(case_when(
  ENTL301 %in% c("aus sonstigen Gründen beendet", "gegen ärztlichen Rat beendet", "gegen ärztlichen Rat beendet, nachstat. Beh. vorgeseh.") ~ 1,
  ENTL301 %in% c("regulär", "beendet, nachstat. Beh. vorgesehen", "Verlegung in ein anderes Krankenhaus", "Rehaeinrichtung", "Pflegeeinrichtung",
                 "aus sonst. Gründen beend., nachstat. Beh. Vorges.", "interne Verlegung m. Wechsel zw. D. Gelt.b. BPflV u. KHEntgG", "Fallabschl. (int. V.) b. Wechsel zw. Voll- und teilst. Beh.") ~ 0,
  TRUE ~ NA_real_), levels = c(0, 1), labels = c("nein", "ja")))

table(inpat$unpl_drop, useNA = "ifany")
prop.table(table(inpat$unpl_drop, useNA = "ifany"))
ggplot(inpat, aes(x = unpl_drop, y = n.days)) + geom_violin() + geom_boxplot(width = 0.1) + theme(axis.text.x = element_text(angle = 35, hjust = 1)) + ylim(NA, 75)

#Fallzahl
inpat %>% summarise(n = n(), npragmaid = n_distinct(pragmaid))

```

### Validierung der ENTLASS301 Variable an Behandlungsdauer

```{r check_ENTL301}
#prop.table(table(inpat$ENTL301))

#ggplot(inpat, aes(x = ENTL301)) + geom_bar() + theme(axis.text.x = element_text(angle = 25, hjust = 1))

#add Anzahl Tage in Behandlung
#qwt <- qwt %>% 
#  mutate(n.days = as.integer(difftime(as.Date(date.qwt.end), as.Date(date.qwt.start), units = "days")) + 1)


#summary(qwt$n.days)
#summary(inpat$n.days)
#IQR(qwt$n.days)
#IQR(inpat$n.days)
#check outliers
#boxplot(qwt$n.days)
#boxplot(inpat$n.days) #sehr viele Ausreißer, Maximum 365 Tage

# bind datasets for plotting purposes
#inpat$dataset <- "inpat"
#qwt$dataset <- "qwt"

#qwt_inpat <- bind_rows(
#  inpat %>% select(ENTL301, n.days, dataset),
#  qwt %>% select(ENTL301, n.days, dataset)
#)


#ggplot(qwt_inpat, aes(x = ENTL301)) + geom_bar() + theme(axis.text.x = element_text(angle = 25, hjust = 1)) + facet_wrap(~dataset)
#INPAT hat größeren Anteil "gegen ärztlichen Rat beendet" und "aus sonstigen Gründen beendet" verglichen mit QWT

#ggplot(qwt_inpat %>% filter(ENTL301 != "Tod"), aes(x = dataset, y = n.days)) +
#  geom_jitter(alpha=0.2, size = rel(0.8), height = 0.2) +
#  geom_violinhalf(width = 0.3, outlier.shape = NA) +
#  geom_boxplot(width = 0.05, outlier.shape = NA) +
#  scale_y_continuous(limits = c(0, 60), breaks = seq(0, 60, by = 5))


#treatdur_ETNL_qwt_inpat <- ggplot(qwt_inpat %>% filter(ENTL301 != "Tod"), aes(x = ENTL301, y = n.days)) + 
#  geom_jitter(alpha = 0.1, size = rel(0.65)) +
#  geom_boxplot(width = 0.34, outlier.shape = NA, alpha = 0.7) +
#  facet_grid(dataset ~ .) +
#  scale_y_continuous(limits = c(0, 50), breaks = seq(0, 50, by = 10)) +
  #change y axis label
#  ylab("Anzahl Tage in QE") +
#  xlab("Entlassungsgrund (ENTL301)") +
  #change legend title
#  labs(title = "Dauer einer Behandlung nach Entlassungsgrund und Treatment unter GKV Versicherten") +
#  theme_minimal() +
#  theme(axis.text.x = element_text(angle = 35, hjust = 1, size = rel(0.85)))

#save plot to doc
#graph2doc(x = treatdur_ETNL_qwt_inpat, file=file.path(folder_plot, "treatdur_ETNL_qwt_inpat.png"), width=10, height=7)
```

Die Variable ENTL301 gibt den Entlassungsgrund an. Die meisten Behandlungen werden regulär beendet, wobei auffällig ist, dass es unter diesen viele Behandlungen gibt, die nur wenige Tage dauern. Es gibt eine dern QWT Behandlungen ähnliche, aber nicht ganz so stark ausgepärgte zweigipfelige Verteilung der Behandlungsdauer bei den regulär beendeten Behandlungen mit einem Peak um eine Woche und 21 Tage. Die ENTL301-Variable wird trotz dieser Inkonsistenzen verwendet, um einen ungeplanten Dropout zu operationalisieren.

Als alternative Operationalisierung der AV Behandlungserfolg des Aufenthalts stattdessen (wie mit den QWT Daten) die Anzahl der Tage in Behandlung heranzuziehen, macht hier nicht so viel Sinn, weil die Varianz sehr groß ist und es kaum extrerne Validierung gibt und die inhaltliche Bedeutung unklar ist. Dementsprechend müssen wir auf die ENTL301 zurückgreifen. 

# Prädiktoren

## Validierung inpat_id

```{r check_qwt_id}
# does the inpat_id increases with increasing date.treat.start?
inpat_check <- inpat %>% 
  group_by(pragmaid) %>%
  arrange(date.treat.start) %>%
  mutate(inpat_id_ordered = row_number()) %>%
  select(pragmaid, inpat_id, inpat_id_ordered, date.treat.start, date.treat.end) #inpat_id was unordered before. therefore, replace inpat_id with inpat_id_ordered

#correct inpat_id, so that it is ordered by date.treat.start
inpat <- inpat %>% 
  group_by(pragmaid) %>%
  arrange(date.treat.start) %>%
  mutate(inpat_id = row_number() - 1) %>%
  mutate(treat_dur_cat = factor(case_when(
  #more than or 20 days in treatment
  n.days >= 21 ~ 3,
  #between 7 and 19 days (inclusive)
  n.days >= 7 & n.days < 21 ~ 2,
  #between 0 and 6 days (inclusive)
  n.days >= 0 & n.days < 7 ~ 1,
  TRUE ~ NA_real_), levels = c(1, 2, 3), labels = c("1-6 Tage","7-20 Tage", "21+ Tage")))

```

## Hinzufügen der Stammdaten - SEX + AGE + NATIONALITY

```{r add_stammdaten}
#match pragma_id_GKV with inpat based on pragma_id to get sex and age information 
total_stamm <- left_join(inpat, pragma_id_GKV, by="pragmaid")

table(total_stamm$gkv.x, useNA = "always")
table(total_stamm$gkv.y, useNA = "always") # 7 cases that are insured by both AOK and DAK (this information is not needed for the analysis, so keep only the insurence information from gkv.x)

total_stamm <- total_stamm %>% 
  select(c(-hivid, -gkv.id, -dak.id, -aok.id, - gkv.y)) %>%
  mutate(age = as.integer(substr(date.treat.start, 1, 4)) - yob) %>% #calculate age at the beginning of the inpatient treatment
  rename(gkv = gkv.x) #rename gkv.x to gkv

table(total_stamm$sex, useNA = "always") # 0 NAs
summary(total_stamm$age) # 0 NAs
```

## Hinzufügen Emplyoment Status

```{r add_employment}
nrow(distinct(total_stamm, pragmaid, inpat_id)) #3833 Fälle bzw 3885 Fälle (je nach Ausschluss von overlapping bzw. direkten Anschlüssen)
employ_unfiltered <- left_join(total_stamm, employment, by = "pragmaid")

table(employ_unfiltered$gkv.x, useNA = "always")
table(employ_unfiltered$gkv.y, useNA = "always") #same

employ_unfiltered <- employ_unfiltered %>% 
  select(- gkv.y) %>%
  rename(gkv = gkv.x) #rename gkv.x to gkv

inpat_employ <- employ_unfiltered %>%
  filter(date.treat.start >= date.emp.start & date.treat.start <= date.emp.end)

nrow(distinct(inpat_employ, pragmaid, inpat_id))
nrow(inpat_employ) - nrow(total_stamm) # there are 30 cases less than before - why?

missing_rows <- total_stamm %>%
  anti_join(inpat_employ, by = c("pragmaid", "inpat_id"))

employment %>% filter(pragmaid %in% missing_rows$pragmaid) %>% group_by(pragmaid) # no employment data for the inpat duration of these cases - why? 
```

### Sind fehlende Daten für Employment auf Unterbrechungen in Versichertenzeiten zurückzuführen?

```{r check_missing_employment}
#check if missing employment data is due to interruptions in insured periods
check_missing <- left_join(missing_rows, insurance_periods, by = c("pragmaid")) %>%
  select(pragmaid, date.treat.start, date.treat.end, date.ins.start, date.ins.end, gkv.x) 

#filter cases where the inpat treatment is covered by insurance
cases_with_valid_ins <- check_missing %>% filter(date.treat.start >= date.ins.start & date.treat.start <= date.ins.end) #there are 8 cases that do have insurance data for the inpatient treatment, but have no corresponding employment data. these cases should be kept in the inpat_employ dataset, as they are insured during the inpatient treatment and the employment status should be set to NA.

# -> some, but not all cases with missing employment data are due to interruptions in insured periods

#add cases with valid insurance to inpat_employ
inpat_employ <- bind_rows(inpat_employ, total_stamm %>% filter(pragmaid %in% cases_with_valid_ins$pragmaid & date.treat.start %in% cases_with_valid_ins$date.treat.start))

table(inpat_employ$emp.type, useNA = "always") # 8 NAs, so the 8 cases without employment infos, but with insurance are added to the inpat_employ dataset
```

## Hinzufügen von Diagnose-Daten

```{r add_diagnoses}
sum(is.na(all_diagnoses$pragmaid)) #158 -> why?

table(all_diagnoses$icd_type)

# keep only diagnoses of patients in inpat_employ, with icd_type confirmed, primary, secondary, any and that are not alcohol related
diagnoses_inpat <- all_diagnoses %>% 
  filter(pragmaid %in% inpat_employ$pragmaid) %>% #keep only rows that are in inpat data 
  filter(icd_type %in% c("confirmed", "primary", "secondary", "any")) %>%
  filter(icd.alc == FALSE) %>% #keep only diaignoses that are not alcohol related (as all inpat cases are alcohol related)
  mutate(length_diag = as.integer(difftime(as.Date(date.diag.end), as.Date(date.diag.start), units = "days"))) 

#check
nrow(distinct(inpat_employ, pragmaid)) - nrow(distinct(diagnoses_inpat, pragmaid)) # 2 patients do not have any diagnoses that matches the criteria

summary(diagnoses_inpat$length_diag)

#plot histogram of length_diag
ggplot(diagnoses_inpat, aes(x = length_diag)) + geom_histogram(binwidth = 1) +
  facet_wrap(~setting, scales = "free_y") +
  scale_x_continuous(limits = c(0, 100))

#show cases with NA in length_diag
diagnoses_inpat %>% 
  filter(is.na(date.diag.start)) %>%
  select(pragmaid, icd, icd_type, setting, date.diag.start, date.diag.end)

#delete length_diag
diagnoses_inpat <- select(diagnoses_inpat, -length_diag)

# if date.diag.start is NA, set it to date.diag.end
diagnoses_inpat <- diagnoses_inpat %>% 
  mutate(date.diag.start = dplyr::if_else(is.na(date.diag.start), date.diag.end, date.diag.start))

# join diagnoses with inpat_employ
diagnoses_inpat_employ_alltimes <- left_join(inpat_employ, diagnoses_inpat, by = c("pragmaid")) 

#check
nrow(distinct(diagnoses_inpat_employ_alltimes, pragmaid, inpat_id)) #3865 -> okay ( originally 3887 cases - 22 cases without valid insurance)

# keep only diagnoses in the timeframe of interest (maximum 2 quarters before inpat start)
diagnoses_inpat_employ_fil <- diagnoses_inpat_employ_alltimes %>%
  filter(
    #Ambulante Diagnosen (Dauer: 1 Quartal) dürfen nicht später zurückliegend als 2 Quartale vor QWT-Start gestellt worden sein und maximal gleich QWT-Start liegen
     date.diag.start >= (date.treat.start - days(180)) & date.diag.start <= date.treat.start)
#Arbeitsdefinition, evtl für stationäre Diagnosen (bzw. alle anderen settings) Eingrenzung anpassen?

sum(diagnoses_inpat_employ_fil$gkv.x != diagnoses_inpat_employ_fil$gkv.y) # 33 cases where the insurance information is not the same in the diagnoses data and the inpat data

diagnoses_inpat_employ_fil %>% filter(gkv.x != gkv.y) #these cases all have source == aokdak, so there seems to be an overlap. however, as the gkv information is not that important, we keep the gkv information from the inpat data

diagnoses_inpat_employ_fil <- diagnoses_inpat_employ_fil %>% 
  select(-gkv.y) %>%
  rename(gkv = gkv.x)

nrow(distinct(diagnoses_inpat_employ_fil, pragmaid, inpat_id)) #3842 (before 3865 - 23 cases were excluded as they did not have a diagnosis in the timeframe of interest - they will be added in the end again


# Charlson and Elixhauser Comorbidity Index

diagnoses_inpat_employ_fil$id_pragma_inpat <- paste(diagnoses_inpat_employ_fil$pragmaid, diagnoses_inpat_employ_fil$inpat_id, sep = "_")

comorb_elix <- comorbidity::comorbidity(x=diagnoses_inpat_employ_fil, id = "id_pragma_inpat",
                                code = "icd",map="elixhauser_icd10_quan",
                                assign0 = T, tidy.codes = T)
print(head(comorb_elix))  
comorb_char <- comorbidity::comorbidity(x=diagnoses_inpat_employ_fil, id = "id_pragma_inpat",
                                code = "icd",map="charlson_icd10_quan",
                                assign0 = T,tidy.codes = T)
print(head(comorb_char))  

comorb_elix_sum <- comorb_elix %>%
  #new column with row sums using all columns except id_pragma_inpat
  mutate(elix_sum = rowSums(select(., -id_pragma_inpat))) %>%
  select(id_pragma_inpat, elix_sum)

comorb_char_sum <- comorb_char %>%
  #new column with row sums using all columns except id_pragma_inpat
  mutate(char_sum = rowSums(select(., -id_pragma_inpat))) %>%
  select(id_pragma_inpat, char_sum)

#bind both comorbidity dataframes
comorb_sum <- left_join(comorb_elix_sum, comorb_char_sum, by = "id_pragma_inpat")
print(head(comorb_sum))      

nrow(distinct(inpat_employ, pragmaid, inpat_id)) - nrow(distinct(comorb_sum, id_pragma_inpat)) #23 cases, these have to be added to the comorb_sum dataset 

inpat_employ$id_pragma_inpat <- paste(inpat_employ$pragmaid, inpat_employ$inpat_id, sep = "_")

diagnoses_inpat_employ <- left_join(inpat_employ, comorb_sum, by = "id_pragma_inpat")

#are there missings? 
nrow(inpat_employ) - nrow(diagnoses_inpat_employ) #0
sum(is.na(diagnoses_inpat_employ$elix_sum)) #23 missings
sum(is.na(diagnoses_inpat_employ$char_sum)) #23 missings

#set NAs to 0
diagnoses_inpat_employ <- diagnoses_inpat_employ %>% 
  mutate(elix_sum = replace_na(elix_sum, 0),
         char_sum = replace_na(char_sum, 0))
```

### Diagnose Daten Descriptives

```{r check_ndiagnoses}
#plot histogram of number of diagnoses
ggplot(diagnoses_inpat_employ, aes(x = elix_sum)) + geom_histogram(binwidth = 1)
summary(diagnoses_inpat_employ$elix_sum)
ggplot(diagnoses_inpat_employ, aes(x = char_sum)) + geom_histogram(binwidth = 1)
summary(diagnoses_inpat_employ$char_sum) 
```

## Hinzufügen von Pflegegraden

```{r add_pflegegrad}
table(fosterage$fost.degree, useNA = "always")
# sowohl Pflegegrade (PG) als auch Pflegestufen (PS). Pflegegrade sind ab 2017 gültig, Pflegestufen bis 2016. Wie Pflegestufen in Pflegegrade umrechnen?

fost_inpat <- fosterage %>% 
  filter(pragmaid %in% diagnoses_inpat_employ$pragmaid)

#checks
sum(is.na(fost_inpat$pragmaid)) #0
sum(is.na(fost_inpat$date.fost.start)) #0
nrow(distinct(diagnoses_inpat_employ, pragmaid)) - nrow(distinct(fost_inpat, pragmaid)) #1523 patients do not have fosterage data, 257 have


fost_diagnoses_inpat_employ_alltimes <- left_join(diagnoses_inpat_employ, fost_inpat, by = "pragmaid")


fost_diagnoses_inpat_employ_fil <- fost_diagnoses_inpat_employ_alltimes %>%
  filter((date.treat.start >= date.fost.start & is.na(date.fost.end)) | (date.treat.start >= date.fost.start & date.treat.start <= date.fost.end))

nrow(distinct(fost_diagnoses_inpat_employ_fil, pragmaid)) # 139 patients do have a pflegegrad/stufe during the beginning of the inpatient treatment

# GKV X - GKV Y
sum(fost_diagnoses_inpat_employ_fil$gkv.x != fost_diagnoses_inpat_employ_fil$gkv.y) # 0 cases where the insurance information is not the same in the fosterage data and the inpat data
fost_diagnoses_inpat_employ_fil <- fost_diagnoses_inpat_employ_fil %>% 
  select(-gkv.y) %>%
  rename(gkv = gkv.x) %>% 
  ungroup()

#add fosterage data to diagnoses_inpat_employ and set fosterage to NA if there is no fosterage data
fost_diagnoses_inpat_employ <- diagnoses_inpat_employ %>% 
  left_join(fost_diagnoses_inpat_employ_fil %>% select(id_pragma_inpat, fost.degree), by = "id_pragma_inpat") %>%
  mutate(fost.degree_bin = as.factor(ifelse(is.na(fost.degree), "nein", "ja"))) 

table(fost_diagnoses_inpat_employ$fost.degree_bin, useNA = "always") #253 cases with fosterage degree-> okay

```

## Hinzufügen von Medikation

```{r add_medication}
med_inpat <- medications %>% 
  filter(pragmaid %in% fost_diagnoses_inpat_employ$pragmaid)

#checks
sum(is.na(med_inpat$pragmaid)) #0
sum(is.na(med_inpat$date.med.start)) #0
nrow(distinct(fost_diagnoses_inpat_employ, pragmaid)) - nrow(distinct(med_inpat, pragmaid)) #59 patients do not have medication data, 1721 have

med_fost_diagnoses_inpat_employ_alltimes <- left_join(fost_diagnoses_inpat_employ, med_inpat, by = "pragmaid")
nrow(distinct(med_fost_diagnoses_inpat_employ_alltimes, pragmaid)) # 1780 -> okay

med_fost_diagnoses_inpat_employ_fil <- med_fost_diagnoses_inpat_employ_alltimes %>%
  # only keep medication data that happend during the 3 months before the inpatient treatment
  filter(date.medi.disp >= (date.treat.start - days(30)) & date.medi.disp <= date.treat.start) %>%
  filter(ATC != "")

nrow(distinct(med_fost_diagnoses_inpat_employ_fil, id_pragma_inpat)) # 1513 inpatient treatments have medication data in the timeframe of interest

#GKV X - GKV Y
sum(med_fost_diagnoses_inpat_employ_fil$gkv.x != med_fost_diagnoses_inpat_employ_fil$gkv.y) # 2 cases where the insurance information is not the same in the medication data and the inpat data
med_fost_diagnoses_inpat_employ_fil %>% 
  filter(gkv.x != gkv.y) #these cases all have source == aokdak, so there seems to be an overlap. however, as the gkv information is not that important, we keep the gkv information from the inpat data
med_fost_diagnoses_inpat_employ_fil <- med_fost_diagnoses_inpat_employ_fil %>% 
  select(-c(gkv.y, REZ_ID, LANR_FAGS, date.medi.presc, PZN_ANZ, DDD1000_PK)) %>%
  rename(gkv = gkv.x) %>%
  ungroup()

#new variable with level 2 ATCs (therapeutische Untergruppe)
med_fost_diagnoses_inpat_employ_fil <- med_fost_diagnoses_inpat_employ_fil %>% 
  group_by(id_pragma_inpat) %>%
  mutate(Level2_ATC = substr(ATC, 1, 3)) %>%
  ungroup()

#how many different values of Level2_ATC are there? 
unique_level2_ATCs <- unique(med_fost_diagnoses_inpat_employ_fil$Level2_ATC)
length(unique_level2_ATCs) #70

# welche Untergruppe ist am häufigsten vertreten?
sorted_atc_counts <- med_fost_diagnoses_inpat_employ_fil %>%
  count(Level2_ATC, sort = TRUE) #Psycholeptika (N05) kommt am häufigsten vor

#calculate sum of disting full ATC and level 2 ATC codes
med_fost_diagnoses_inpat_employ_fil <- med_fost_diagnoses_inpat_employ_fil %>%
  group_by(id_pragma_inpat) %>%
  dplyr::summarize(ndistinctATClevel2 = n_distinct(Level2_ATC), 
            ndistinctATC = n_distinct(ATC)) %>%
  ungroup()

table(med_fost_diagnoses_inpat_employ_fil$ndistinctATClevel2)

med_fost_diagnoses_inpat_employ <- left_join(fost_diagnoses_inpat_employ, med_fost_diagnoses_inpat_employ_fil, by = "id_pragma_inpat")

med_fost_diagnoses_inpat_employ <- med_fost_diagnoses_inpat_employ %>%
  mutate(ndistinctATC = ifelse(is.na(ndistinctATC), 0, ndistinctATC)) %>%
  mutate(ndistinctATClevel2 = ifelse(is.na(ndistinctATClevel2), 0, ndistinctATClevel2)) %>%
  mutate(polymedi = as.factor(ifelse(ndistinctATC >= 6, "ja", "nein"))) %>%
  mutate(polymedi_level2 = as.factor(ifelse(ndistinctATClevel2 >= 5, "ja", "nein")))

summary(med_fost_diagnoses_inpat_employ$ndistinctATClevel2)
hist(med_fost_diagnoses_inpat_employ$ndistinctATClevel2)

```
## Hinzufügen von QWT ID (wie viele QWTs hat eine Person zum Zeitpunkt des INPAT treatments bereits gemacht?)

```{r qwt count}

#Daten zusammenführen

med_fost_diagnoses_inpat_employ_qwt <- bind_rows(
  med_fost_diagnoses_inpat_employ, qwt %>% select(pragmaid, date.treat.start, treatment, date.treat.end))

med_fost_diagnoses_inpat_employ_qwt <- med_fost_diagnoses_inpat_employ_qwt %>%
  group_by(pragmaid) %>%
  arrange(date.treat.start) %>%
  mutate(QWT_count_before_INPAT = sapply(1:n(), function(i) {
    if (treatment[i] == "inpat") {
      sum(treatment[1:(i-1)] == "qwt" & date.treat.end[1:(i-1)] < date.treat.start[i])
    } else {
      NA
    }
  }))

#check
med_fost_diagnoses_inpat_employ_qwt %>% select(pragmaid, date.treat.start, inpat_id, treatment, QWT_count_before_INPAT) %>% arrange(pragmaid, date.treat.start) #okay

med_fost_diagnoses_inpat_employ_qwt <- med_fost_diagnoses_inpat_employ_qwt %>% filter(treatment == "inpat")

```

## Hinzufügen von REHA ID (wie viele Rehas hat eine Person zum Zeitpunkt des INPAT treatments bereits gemacht?)

```{r reha count}
#Daten zusammenführen (mit reha statt der reha_new Daten, da in den reha daten sowohl GKV als auch DRV vorhanden sind)

med_fost_diagnoses_inpat_employ_qwt_reha <- bind_rows(
  med_fost_diagnoses_inpat_employ_qwt, reha %>% select(pragmaid, date.treat.start, treatment, date.treat.end))

med_fost_diagnoses_inpat_employ_qwt_reha <- med_fost_diagnoses_inpat_employ_qwt_reha %>%
  group_by(pragmaid) %>%
  arrange(date.treat.start) %>%
  mutate(REHA_count_before_INPAT = sapply(1:n(), function(i) {
    if (treatment[i] == "inpat") {
      sum(treatment[1:(i-1)] == "reha" & date.treat.end[1:(i-1)] < date.treat.start[i])
    } else {
      NA
    }
  }))

#check
med_fost_diagnoses_inpat_employ_qwt_reha %>% select(pragmaid, date.treat.start, inpat_id, treatment, QWT_count_before_INPAT, REHA_count_before_INPAT) %>% arrange(pragmaid, date.treat.start) #okay

med_fost_diagnoses_inpat_employ_qwt_reha <- med_fost_diagnoses_inpat_employ_qwt_reha %>% filter(treatment == "inpat")

#ungroup data
med_fost_diagnoses_inpat_employ_qwt_reha <- med_fost_diagnoses_inpat_employ_qwt_reha %>% ungroup()

```

# Auswahl relevanter Variablen

```{r select_vars}
final_data <- med_fost_diagnoses_inpat_employ_qwt_reha %>% 
  select(-c(KH_FALL_ID, date.treat.start, date.treat.end, date.emp.start, date.emp.end, id_pragma_inpat, fost.degree, source, died, date.death, yob, treatment))
```

# Centering variables

Center all continuous variables (i.e., subtract the mean, so the mean = 0). The coefficients are then interpreted as the change in the log odds of the outcome for a one-unit increase in the predictor, while holding all other predictors at their mean values. The intercept represents the log odds of the outcome when all predictors are at their mean values.


```{r center}  

variables_to_center <- c("age", "inpat_id", "elix_sum", "ndistinctATClevel2", "QWT_count_before_INPAT", "REHA_count_before_INPAT", "char_sum", "n.days")

#centering
for (var in variables_to_center) {
  final_data[[paste0(var, "_cent")]] <- scale(final_data[[var]], center = TRUE, scale = FALSE)
}
```

# Intercorrelation of (numeric) predictors/outcome

```{r correlation}
cor_matrix <-  cor(final_data %>% select(c("age", "inpat_id", "elix_sum", "ndistinctATClevel2", "QWT_count_before_INPAT", "REHA_count_before_INPAT", "char_sum", "n.days_cent")))
cor_matrix
cor_melted <- melt(cor_matrix)

# Erstelle die Heatmap
ggplot(cor_melted, aes(Var1, Var2, fill = value)) +
  geom_tile() +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", midpoint = 0) +
  #add correlation values as text
  geom_text(aes(label = round(value, 2)), vjust = 1) +
  theme_minimal() +
  labs(x = "", y = "", title = "Correlation Heatmap") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# correlation of treatment duration and unplanned dropouts

#with p values
final_data$unpl_drop_numeric <- as.numeric(final_data$unpl_drop) - 1
final_data$treat_dur_cat_numeric <- as.numeric(final_data$treat_dur_cat)

cor.test(final_data$n.days_cent, final_data$unpl_drop_numeric, method = "spearman") # rho: -.37
cor(final_data$treat_dur_cat_numeric, final_data$unpl_drop_numeric, method = "pearson") #-.40

#remove unpl_drop_numeric and n.days_cat_numeric
final_data <- final_data %>% select(-c(unpl_drop_numeric, treat_dur_cat_numeric))
```


# Speicherplatz freigeben

```{r save_data}
#alle Datenfiles die "all" oder "check" oder "missing" im Namen haben, können gelöscht werden
#identifiziere alle Objekte, die gelöscht werden können
objects <- ls()
objects <- objects[grepl("all|check|missing|fil", objects)]
#lösche alle Objekte
rm(list = objects)
#free unused memory
gc()
```

# Überprüfung der Daten vor Modellierung

## Ausreißer, fehlende Werte und Datentypen

```{r check_data}

final_data$emp.type <- as.factor(final_data$emp.type)
final_data$sex <- as.factor(final_data$sex)
final_data$nationality <- as.factor(final_data$nationality)
final_data$gkv <- as.factor(final_data$gkv)

#check for missings
summary(final_data)
anyNA(final_data) #8 NAs in EmpType -> set to "other"
final_data$emp.type[is.na(final_data$emp.type)] <- "other"

##outliers?
## remove #all outliers that match the definition: bigger than 75% quantile + 3*IQR (Tukey's fences)

# inpat_id
boxplot(final_data$inpat_id) # some patients did 30 treatments -> remove them?
#cutoff_inpatid <- quantile(final_data$inpat_id, 0.75) + 3*IQR(final_data$inpat_id)
#cutoff_inpatid
#remove them
#final_data <- final_data %>% filter(inpat_id <= cutoff_inpatid)

# ndays
boxplot(final_data$n.days)# many outliers
cutoff <- quantile(final_data$n.days, 0.75) + 3*IQR(final_data$n.days)
#final_data <- final_data %>% filter(n.days <= cutoff)

# char_sum
boxplot(final_data$char_sum) # some outliers
cutoff_char <- quantile(final_data$char_sum, 0.75) + 3*IQR(final_data$char_sum)
cutoff_char
#final_data <- final_data %>% filter(char_sum <= cutoff_char)

#elix_sum
boxplot(final_data$elix_sum) # some outliers
cuttoff_elix <- quantile(final_data$elix_sum, 0.75) + 3*IQR(final_data$elix_sum)
cuttoff_elix
#final_data <- final_data %>% filter(elix_sum <= cuttoff_elix)

#ndistinctATClevel2
boxplot(final_data$ndistinctATClevel2) # some outliers
cutoff_ndistinctATClevel2 <- quantile(final_data$ndistinctATClevel2, 0.75) + 3*IQR(final_data$ndistinctATClevel2)
cutoff_ndistinctATClevel2
#final_data <- final_data %>% filter(ndistinctATClevel2 <= cutoff_ndistinctATClevel2)

#QWT_count_before_INPAT
boxplot(final_data$QWT_count_before_INPAT)
cutoff_QWT_count_before_INPAT <- quantile(final_data$QWT_count_before_INPAT, 0.75) + 3*IQR(final_data$QWT_count_before_INPAT)
cutoff_QWT_count_before_INPAT
```
## Linearer Zusammenhang mit Logit des Outcomes

Der Zusammenhang zwischen Prädiktoren und der abhängiggen Variablen irreguläre Beendigung der Behandlung soll mittels logistischen Regressionsmodellen geschätzt werden. Dafür muss zunächst die Modellannahme geprüft werden, dass ein linearer Zusammenhang zwischen metrischen Prädikoren und dem Logit des Outcomes besteht. Um diese Annahme zu testen, werden die logistischen Regressionsmodelle geschätzt und zusätzliche Prädiktoren inkludiert, die die Interkation zwischen dem jeweiligen metrischen Prädiktor und deren Logarithmus darstellen (Hosmer & Lemeshow, 1989).
Relevant ist nur, ob die Interaktionstermine signifikant sind. Jede signifikante Interaktion deutet darauf hin, dass der jeweilige Haupteffekt die Annahme der Linearität im Logit verletzt. 

```{r linearity_test}
# Erstellen der Interaktionsterme der metrischen Prädiktoren mit ihrem Logarithmus
final_data$logageInt <- log(final_data$age+1) * final_data$age
final_data$loginpat_idInt <- log(final_data$inpat_id+1) * final_data$inpat_id
final_data$logelix_sumInt <- log(final_data$elix_sum+1) * final_data$elix_sum
final_data$logndistinctATClevel2Int <- log(final_data$ndistinctATClevel2+1) * final_data$ndistinctATClevel2
final_data$logQWT_count_before_INPATInt <- log(final_data$QWT_count_before_INPAT+1) * final_data$QWT_count_before_INPAT
final_data$logREHA_count_before_INPATInt <- log(final_data$REHA_count_before_INPAT+1) * final_data$REHA_count_before_INPAT



outcomes <- c("unpl_drop")


predictors <- "sex + nationality + emp.type + age + fost.degree_bin + logageInt + inpat_id + loginpat_idInt + elix_sum + logelix_sumInt + ndistinctATClevel2 + logndistinctATClevel2Int + QWT_count_before_INPAT + logQWT_count_before_INPATInt + REHA_count_before_INPAT + logREHA_count_before_INPATInt"


models <- list()

# Schleife, um 1 Modell je Outcome zu fitten
for (outcome in outcomes) {
  formula <- as.formula(paste(outcome, "~", predictors))
  models[[outcome]] <- glm(formula, data = final_data, family = binomial(link = "logit"))
  cat("\n\n", outcome, "\n")
  print(summary(models[[outcome]]))
}

```

Linearitätsannahme ist nur für elix_sum verletzt, da signifikante Interaktion. 

# ```{r check_log_transformation}
# 
# 
# data_test <- final_data %>%
#   mutate(bin = cut(elix_sum, breaks = 10)) %>%
#   group_by(bin) %>%
#   summarise(
#     mean_pred = mean(elix_sum, na.rm = TRUE),
#     p = mean(as.numeric(unpl_drop), na.rm = TRUE),
#     logit_p = log(p + 0.001 / (1 - p + 0.001)),  # Logit-Transformation mit Laplace-Korrektur (falls p = 0 oder p = 1)
#     n = n()
#   )
# 
# ggplot(data_test, aes(x = mean_pred, y = logit_p)) +
#   geom_point() +
#   geom_smooth(method = "loess", color = "red", se = FALSE) +
#   geom_text(aes(label = n), hjust = 0, vjust = 0) +
#   labs(
#     title = "Überprüfung der log-linearen Beziehung: elix_sum für unpl_drop",
#     x = "Prädiktor elix_sum",
#     y = "Logit(P(Y=1))"
#   )

#```
<!-- Logarithmische Transformation scheitn ungeeignet, daher wird hier kategorisiert.  -->

<!-- ```{r categorize_elix}   -->
<!-- #tertile limits -->
<!-- tertile_limits_e <- quantile(final_data$elix_sum[final_data$elix_sum > 0], probs = c(0.33, 0.66)) -->

<!-- final_data <- final_data %>% mutate( -->
<!--   elix_sum_cat = case_when( -->
<!--     elix_sum == 0 ~ "0", -->
<!--     elix_sum <= tertile_limits_e[1] ~ "1-2", -->
<!--     elix_sum <= tertile_limits_e[2] ~ "3", -->
<!--     TRUE ~ "4+" -->
<!--   ) %>% factor(levels = c("0", "1-2", "3", "4+")) -->
<!-- ) -->

<!-- # Check -->
<!-- table(final_data$elix_sum_cat, final_data$elix_sum, useNA = "always") -->
<!-- table(final_data$elix_sum_cat) -->
<!-- ``` -->
## Multicollinearity

```{r multicollinearity}
vif_model <- glm(unpl_drop ~ sex + age_cent + inpat_id_cent + nationality + emp.type + elix_sum_cent + fost.degree_bin + ndistinctATClevel2_cent + QWT_count_before_INPAT_cent + REHA_count_before_INPAT_cent, family = "binomial", data = final_data)

car::vif(vif_model) #no multicollinearity

#"A consequence is that when using adjusted generalized standard error inflation factor (GSIF = GVIF^(1/(2*Df)), we must take the square-root of our rules of thumb for what is a large value – aGSIF values above √2.5 (1.6) may be of concern, and values above √5 or √10 (2.2 or 3.2) are indicative of a more serious problem"

#correlation matrix
#raq_poly <- psych::polychoric(items)
#raq_cor <- raq_poly$rho
#round(raq_cor, 2)
#psych::cor.plot(raq_cor, upper = FALSE)

```

#Logistische Modelle

```{r log_models}
# Initialisiere einen leeren DataFrame für die Modellanpassungsparameter
model_summaries <- data.frame(
  Model = character(),
  Deviance = numeric(),
  AIC = numeric(),
  BIC = numeric(),
  stringsAsFactors = FALSE
)

add_model_summary <- function(model, model_name) {
#  summary <- summary(model)
#  stats <- summary$sumstat
  model_summaries <<- rbind(model_summaries, data.frame(
    Model = model_name,
    LogLik = logLik(model),
    AIC = AIC(model),
    BIC = BIC(model)
  ))
}

#nur Intercept und random effects
model1 <- glmmTMB(unpl_drop ~ 1 + (1|pragmaid), family = "binomial", data = final_data) #unconditional model
summary(model1)
add_model_summary(model1, "Intercept")


model2 <- glmmTMB(unpl_drop ~ sex + (1|pragmaid), family = "binomial", data = final_data) #model 2 führt zu Verbesserungen
summary(model2)
add_model_summary(model2, "Model 2")


model3 <- glmmTMB(unpl_drop ~ sex + age_cent + (1|pragmaid), family = "binomial", data = final_data)
summary(model3)
add_model_summary(model3, "Model 3")

model4 <- glmmTMB(unpl_drop ~ sex + age_cent + inpat_id_cent + (1|pragmaid), family = "binomial", data = final_data)
summary(model4) # Modell 4 bietet keinen Vorteil gegenüber Modell 3 -> INPAT ID rauslassen?
add_model_summary(model4, "Model 4")

model5 <- glmmTMB(unpl_drop ~ sex + age_cent + inpat_id_cent + nationality + (1|pragmaid), family = "binomial", data = final_data)
summary(model5) # Modell 5 bietet keinen Vorteil gegenüber Modell 3 (außer leicht niedrigerer deviance)
add_model_summary(model5, "Model 5")


model6 <- glmmTMB(unpl_drop ~ sex + age_cent + inpat_id_cent + nationality + emp.type + (1|pragmaid), family = "binomial", data = final_data)
summary(model6) # Model 6 hat besseres AIC und deviance als Modell 3, aber schlechteres BIC
add_model_summary(model6, "Model 6")

model7 <- glmmTMB(unpl_drop ~ sex + age_cent + inpat_id_cent+ nationality + emp.type + elix_sum_cent + (1|pragmaid), family = "binomial", data = final_data)
summary(model7)
add_model_summary(model7, "Model 7")


# ist char_sum ein besserer Prädiktor?
model8 <- glmmTMB(unpl_drop ~ sex + age_cent + inpat_id_cent + nationality + emp.type + char_sum_cent + (1|pragmaid), family = "binomial", data = final_data)
summary(model8)
add_model_summary(model8, "Model 8") # char_sum passt schlechter als elix_sum_cent, ist aber auch signifikant

model9 <- glmmTMB(unpl_drop ~ sex + age_cent + inpat_id_cent + nationality + emp.type + elix_sum_cent + fost.degree_bin + (1|pragmaid), family = "binomial", data = final_data)
summary(model9)
add_model_summary(model9, "Model 9") # keine Verbesserung gegenüber Modell 8

model10 <- glmmTMB(unpl_drop ~ sex + age_cent + inpat_id_cent + nationality + emp.type + elix_sum_cent + fost.degree_bin + ndistinctATClevel2_cent + (1|pragmaid), family = "binomial", data = final_data)
summary(model10)
add_model_summary(model10, "Model 10") 

model11 <- glmmTMB(unpl_drop ~ sex + age_cent + inpat_id_cent + nationality + emp.type + elix_sum_cent + fost.degree_bin + ndistinctATClevel2_cent + (1|pragmaid), family = "binomial", data = final_data)
summary(model11)
add_model_summary(model11, "Model 11") 


model12 <- glmmTMB(unpl_drop ~ sex + age_cent + inpat_id_cent + nationality + emp.type + elix_sum_cent + fost.degree_bin + ndistinctATClevel2_cent + QWT_count_before_INPAT_cent + (1|pragmaid), family = "binomial", data = final_data)
summary(model12)
add_model_summary(model12, "Model 12") 

model13 <- glmmTMB(unpl_drop ~ sex + age_cent + inpat_id_cent+ nationality + emp.type + elix_sum_cent + fost.degree_bin + ndistinctATClevel2_cent + QWT_count_before_INPAT_cent + REHA_count_before_INPAT_cent + (1|pragmaid), family = "binomial", data = final_data) #Hinzunahme von REHA_count_before_INPAT_cent ist nicht signifikant und verschlechtert model fit (auch wenn Reihenfolge umgekehr, dh wenn erst REHA count und dann QWT count aufgenommen wird)
summary(model13)
add_model_summary(model13, "Model 13") 
```

# Interaktionen mit inpat_id
```{r interactions}
model14 <- glmmTMB(unpl_drop ~ sex + age_cent + inpat_id_cent + nationality + emp.type + elix_sum_cent + fost.degree_bin + ndistinctATClevel2_cent + QWT_count_before_INPAT_cent + REHA_count_before_INPAT_cent + inpat_id_cent*age_cent + (1|pragmaid), family = "binomial", data = final_data) #Hinzunahme von Interaktion inpat_id*age_cent verbessert AIC und LogLik leicht, age_cent:inpat_id_cent knapp nicht signifikant
summary(model14)
add_model_summary(model14, "Model 14") 
anova(model13, model14, test = "LRT") 
anova(model1, model13, test = "LRT") 

model15 <- glmmTMB(unpl_drop ~ sex + age_cent + inpat_id_cent+ nationality + emp.type + elix_sum_cent + fost.degree_bin + ndistinctATClevel2_cent + QWT_count_before_INPAT_cent + REHA_count_before_INPAT_cent + inpat_id_cent*sex + (1|pragmaid), family = "binomial", data = final_data) 
#Interaktion inpat_id_cent*sex ist nicht signifikant
summary(model15)
add_model_summary(model15, "Model 15") 

model16 <- glmmTMB(unpl_drop ~ sex + age_cent + inpat_id_cent+ nationality + emp.type + elix_sum_cent + fost.degree_bin + ndistinctATClevel2_cent + QWT_count_before_INPAT_cent + REHA_count_before_INPAT_cent + inpat_id_cent*elix_sum_cent + (1|pragmaid), family = "binomial", data = final_data)
summary(model16) #inpat_id_cent:elix_sum_cent nicht signifikant
add_model_summary(model16, "Model 16") 


model17 <- glmmTMB(unpl_drop ~ sex + age_cent + inpat_id_cent+ nationality + emp.type + elix_sum_cent + fost.degree_bin + ndistinctATClevel2_cent + QWT_count_before_INPAT_cent + REHA_count_before_INPAT_cent + inpat_id_cent*nationality + (1|pragmaid), family = "binomial", data = final_data) 
summary(model17) #inpat_id_cent:nationality nicht signifikant
add_model_summary(model17, "Model 17") 

model_18 <- glmmTMB(unpl_drop ~ sex + age_cent + inpat_id_cent+ nationality + emp.type + elix_sum_cent + fost.degree_bin + ndistinctATClevel2_cent + QWT_count_before_INPAT_cent + REHA_count_before_INPAT_cent + inpat_id_cent*emp.type + (1|pragmaid), family = "binomial", data = final_data)
summary(model_18) #inpat_id_cent:emp.type nicht signifikant
add_model_summary(model_18, "Model 18")

model_19 <- glmmTMB(unpl_drop ~ sex + age_cent + inpat_id_cent+ nationality + emp.type + elix_sum_cent + fost.degree_bin + ndistinctATClevel2_cent + QWT_count_before_INPAT_cent + REHA_count_before_INPAT_cent + inpat_id_cent*fost.degree_bin + (1|pragmaid), family = "binomial", data = final_data)
summary(model_19) #inpat_id_cent:fost.degree_bin nicht signifikant
add_model_summary(model_19, "Model 19")

model_20 <- glmmTMB(unpl_drop ~ sex + age_cent + inpat_id_cent+ nationality + emp.type + elix_sum_cent + fost.degree_bin + ndistinctATClevel2_cent + QWT_count_before_INPAT_cent + REHA_count_before_INPAT_cent + inpat_id_cent*ndistinctATClevel2_cent + (1|pragmaid), family = "binomial", data = final_data)
summary(model_20) #inpat_id_cent:ndistinctATClevel2_cent nicht signifikant
add_model_summary(model_20, "Model 20")

model_21 <- glmmTMB(unpl_drop ~ sex + age_cent + inpat_id_cent+ nationality + emp.type + elix_sum_cent + fost.degree_bin + ndistinctATClevel2_cent + QWT_count_before_INPAT_cent + REHA_count_before_INPAT_cent + inpat_id_cent*QWT_count_before_INPAT_cent + (1|pragmaid), family = "binomial", data = final_data)
summary(model_21) #inpat_id_cent:QWT_count_before_INPAT_cent nicht signifikant
add_model_summary(model_21, "Model 21")

model_22 <- glmmTMB(unpl_drop ~ sex + age_cent + inpat_id_cent+ nationality + emp.type + elix_sum_cent + fost.degree_bin + ndistinctATClevel2_cent + QWT_count_before_INPAT_cent + REHA_count_before_INPAT_cent + inpat_id_cent*REHA_count_before_INPAT_cent + (1|pragmaid), family = "binomial", data = final_data)
summary(model_22) #inpat_id_cent:REHA_count_before_INPAT_cent nicht signifikant
add_model_summary(model_22, "Model 22")

```

# Evaluate model fit

```{r model_fit}
#find the best fitting model
choose_best_model <- function(summary_df, criterion) {
  if (!criterion %in% names(summary_df)) {
    stop("Ungültiges Kriterium. Wähle entweder 'LogLik', 'AIC' oder 'BIC'.")
  }

  if (criterion == "LogLik") {
    best_model_row <- summary_df[which.max(summary_df[[criterion]]), ]
  } else {
    best_model_row <- summary_df[which.min(summary_df[[criterion]]), ]
  }

  return(best_model_row)
}

choose_best_model(model_summaries, "BIC") 
choose_best_model(model_summaries, "AIC") 
choose_best_model(model_summaries, "LogLik") 

#plot model summaries as skree plot
model_summaries_long <- model_summaries %>%
  pivot_longer(cols = c(LogLik, AIC, BIC), names_to = "Criterion", values_to = "Value")

#desired order of models: intercept, model 2, model 3, model 4, model 5, model 6, model 7, model 8, model 9, model 10, model 11, model 12, model 13, model 14, model 15, model 16, model 17
model_summaries_long$Model <- factor(model_summaries_long$Model, levels = c("Intercept", "Model 2", "Model 3", "Model 4", "Model 5", "Model 6", "Model 7", "Model 8", "Model 9", "Model 10", "Model 11", "Model 12", "Model 13", "Model 14", "Model 15", "Model 16", "Model 17", "Model 18", "Model 19", "Model 20", "Model 21", "Model 22"))

ggplot(model_summaries_long, aes(x = Model, y = Value, color = Criterion)) +
  geom_point(stat = "identity") +
  geom_line(aes(group = Criterion)) +
  facet_wrap(~Criterion, scales = "free_y") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(
    title = "Model Comparison",
    x = "Model",
    y = "Criterion Value"
  )


#Ist Modelverbesserung signifikant durch Hinzunahme von inpat_id_cent*sex?
d14 <- as.numeric(-2*logLik(model14)) #is the -2LL for mod0
d15 <- as.numeric(-2*logLik(model15)) #is the -2LL for mod2
ldif <- d14 - d15 #is the -2LL difference
degfr <- 1 #difference in the number of parameters. degfr is 1 because mod15 has one extra parameter
##compute the p-value.
pchisq(ldif, degfr, lower.tail = FALSE) #.14
#the -2LL of Model15 is not significantly closer to 0

Anova(model12)
Anova(model12,type="III") # to do: set sum-to-zero contrasts on factors and center numerical covariates

```

# Decide on best model 
```{r best_model}
best_model <- model13
```

# Model diagnostics: ICC and R2
```{r model_iccr2}
#R2 = proportion of the explained variance (of the full model)
performance::r2_nakagawa(best_model) #conditional R2: 21.3%, marginal R2: 4.8%

# ICC = proportion of explained variance that can be attributed to the random effects
residual_var <- pi^2 / 3
random_effects_var <- as.numeric(VarCorr(best_model)$pragmaid[1])
ICC <- random_effects_var / (random_effects_var + residual_var)
print(ICC) #.173
performance::icc(best_model) #etwa 17% der outcomevarianz wird durch unterschiede in den gruppen (pragmaID) erklärt

anova(model1, best_model, test = "Chisq") 


```
## Odds Ratios of significant predictors
```{r odds_ratios}
# Odds Ratios
coefficents <- summary(best_model)$coefficients$cond[, 1]
se <- summary(best_model)$coefficients$cond[, 2]

odds_ratios <- exp(coefficents) #odds ratios

#95% confidence intervals
ci_lower <- exp(coefficents - 1.96 * se)
ci_upper <- exp(coefficents + 1.96 * se)

#combine into a data frame
odds_ratios_df <- data.frame(
  Predictor = names(coefficents),
  OR = odds_ratios,
  CI_lower = ci_lower,
  CI_upper = ci_upper,
  p = summary(best_model)$coefficients$cond[, 4]
)
rownames(odds_ratios_df) <- NULL
```


# Fallzahlen und Stichprobenbeschreibung
```{r sample_size}
# wie viele patients?
n_pat <- final_data %>% distinct(pragmaid) %>% nrow()
# wie viele Behandlungen?
n_treats <- final_data %>% nrow()

print(n_pat)
print(n_treats)

#share dropouts
prop.table(table(final_data$unpl_drop))

#AGE
summary(final_data$age)
sd(final_data$age)

#SEX
prop.table(table(final_data$sex))

#emp.type
prop.table(table(final_data$emp.type))

#nationality
prop.table(table(final_data$nationality))

#elix_sum
summary(final_data$elix_sum)

#ndistinctATClevel2
summary(final_data$ndistinctATClevel2)

#fost.degree_bin
prop.table(table(final_data$fost.degree_bin))

#REHA_count_before_inpat
summary(final_data$REHA_count_before_INPAT)

#QWT_count_before_INPAT
summary(final_data$QWT_count_before_INPAT)

#inpat_id
summary(final_data$inpat_id)

#anzahl distinkter pragmaIDs mit qwt_id > 0 / anzahl aller distinkter pragmaIDs = anteil der patienten mit mehr als einer QWT
(final_data %>% filter(inpat_id > 0) %>% distinct(pragmaid) %>% nrow()) / n_pat 
#mehr als 2 QWTs
(final_data %>% filter(inpat_id > 1) %>% distinct(pragmaid) %>% nrow()) / n_pat
#mehr als 3 QWTs
(final_data %>% filter(inpat_id > 2) %>% distinct(pragmaid) %>% nrow()) / n_pat
#mehr als 4 QWTs
(final_data %>% filter(inpat_id > 4) %>% distinct(pragmaid) %>% nrow()) / n_pat

#average number of treatments per patient
#INPAT
n_treats_inpat <- final_data %>% group_by(pragmaid) %>% summarise(n_treats = n()) %>% pull(n_treats)
summary(n_treats_inpat)

#REHA
n_treats_reha <- final_data %>%
  group_by(pragmaid) %>%
  slice_max(REHA_count_before_INPAT, with_ties = FALSE) %>% 
  ungroup() %>%
  pull(REHA_count_before_INPAT)
summary(n_treats_reha)

#QWT
n_treats_qwt <- final_data %>%
  group_by(pragmaid) %>%
  slice_max(QWT_count_before_INPAT, with_ties = FALSE) %>% 
  ungroup() %>%
  pull(QWT_count_before_INPAT)
summary(n_treats_qwt)


```
# Predicted Probabilities

```{r plot_pred_probs}
# Predicted probabilities
new_labels <- c(
  "(Intercept)" = "Intercept", 
  "age_cent" = "Alter",
  "inpat_id_cent" = "Behandlungserfahrung SAB",
  "sexmale" = "Geschlecht: männlich\n(Ref.: weiblich)",
  "nationalitynicht deutsch" = "Nationalität: deutsch\n(Ref.: nicht-deutsch)",
  "emp.typeother" = "Beschäftigungsstatus: andere\n(Ref.: erwerbstätig)",
  "emp.typeunemployed" = "Beschäftigungsstatus: arbeitslos\n(Ref.: erwerbstätig)",
  "emp.typeretired" = "Beschäftigungsstatus: Rente\n(Ref.: erwerbstätig)",
  "elix_sum_cent" = "Elixhauser-Score",
  "fost.degree_binja" = "Pflegestatus: vorhanden\n(Ref.: nicht vorhanden)",
  "ndistinctATClevel2_cent" = "Anzahl Medikationen",
  "QWT_count_before_INPAT_cent" = "Behandlungserfahrung QWT",
  "REHA_count_before_INPAT_cent" = "Behandlungserfahrung REHA"
)


coefffix_plot <- sjPlot::plot_model(best_model, vline.color = "black", show.values = TRUE, value.offset = .4, value.size = 3.5, dot.size = 2, sort.est = TRUE, axis.labels = new_labels, title = "", color = c("blue", "red"),  axis.lim = c(0.6, 3), wrap.labels = 100)

coefffix_plot <- coefffix_plot + 
  #change size of axis labels
  theme_minimal() +
  theme(axis.text.y = element_text(size = 12))
  
coefffix_plot

#save plot
graph2doc(x = coefffix_plot, file=file.path(folder_plot, "coefffix_plot_INPAT.png"), width=7.5, height=4.5)

#

plot(ggpredict(best_model, terms = c("age_cent", "inpat_id_cent")))

#graph2doc(x = coefffix_plot, file=file.path(folder_plot, "coefffix_plot_inpat.png"), width=7, height=5)

#effekte der prädiktoren unter konstanthaltung aller anderen prädiktoren
ae <- allEffects(model14)
plot(ae)

plot(ae["age_cent:inpat_id_cent"])
plot(ae["sex"])
plot(ae["elix_sum_cent"])
plot(ae["treat_dur_cat"])
plot(ae["REHA_count_before_INPAT_cent"])

#Interaktion zwischen inpat_id und age: bei geringer bzw. durchschnittlicher Anzahl von Behandlungen nimmt die Wahrscheinlichkeit eines Abbruchs stärker mit dem Alter ab. Bei einer höheren Anzahl von Behandlungen (! SD über dem Mittelwert) gibt es keinen Einfluss des Alters auf die Wahrscheinlichkeit eines Abbruchs.
```

# model checking and diagnostics

```{r residuals}

model_simres <- simulateResiduals(best_model)
plot(model_simres)
```
Keine signifikante Abweichung in der Verteilung der Residuen (p-Wert des KS-Tests > 0.05).
Keine Anzeichen von Überdispersion (Dispersionstest nicht signifikant).
Keine Ausreißer (Outlier-Test p = 1).
Visuell zeigen die Residuen keine systematischen Muster.


# Fallzahlen
```{r sample_size}
# wie viele patients?
n_pat <- final_data %>% distinct(pragmaid) %>% nrow()
# wie viele Behandlungen?
n_treats <- final_data %>% nrow()

print(n_pat)
print(n_treats)

#share of dropouts
prop.table(table(final_data$unpl_drop))
```




# OLD:
```{r OLD}
#nur Intercept und random effects
model1 <- mblogit(formula = treat_dur_cat ~ 1, random = ~ 1 | pragmaid, data = final_data)
getSummary.mblogit(model1)
add_model_summary(model1, "Intercept")

glmmTMB(unpl_drop ~ sex + age + qwt_id + nationality + emp.type + elix_sum + fost.degree_bin + polymedi + (1|pragmaid), data = final_data, family = binomial)



model2 <- mblogit(formula = treat_dur_cat ~ sex, random = ~ 1 | pragmaid, data = final_data) #model 2 führt zu keiner Verbesserungen (lediglich etwas geringere deviance)
getSummary.mblogit(model2)
add_model_summary(model2, "Model 2")


model3 <- mblogit(formula = treat_dur_cat ~ sex + age, random = ~ 1 | pragmaid, data = final_data)
getSummary.mblogit(model3) #Modell 3 hat die besten Anpassungswerte basierend auf Devianz, AIC und BIC. "age" scheint ein signifikanter Prädiktor für die Kategorien „7–20 Tage“ und „21+ Tage“ im Vergleich zu „1-6 Tage“ zu sein.
add_model_summary(model3, "Model 3")

model4 <- mblogit(formula = treat_dur_cat ~ sex + age + inpat_id, random = ~ 1 | pragmaid, data = final_data)
getSummary.mblogit(model4) # Modell 4 bietet keinen Vorteil gegenüber Modell 3
add_model_summary(model4, "Model 4")

model5 <- mblogit(formula = treat_dur_cat ~ sex + age + inpat_id + nationality, random = ~ 1 | pragmaid, data = final_data)
getSummary.mblogit(model5) # Modell 5 bietet keinen Vorteil gegenüber Modell 3 (außer leicht niedrigerer deviance), nationality wird nicht in das modell aufgenommen
add_model_summary(model5, "Model 5")


model6 <- mblogit(formula = treat_dur_cat ~ sex + age + inpat_id + emp.type, random = ~ 1 | pragmaid, data = final_data)
getSummary.mblogit(model6) # Model 6 hat besseres AIC und deviance als Modell 3, aber schlechteres BIC
add_model_summary(model6, "Model 6")

model7 <- mblogit(formula = treat_dur_cat ~ sex + age + inpat_id + emp.type + gkv, random = ~ 1 | pragmaid, data = final_data) # Model 7 bietet keinen Vorteil gegenüber Modell 6
getSummary.mblogit(model7)
add_model_summary(model7, "Model 7")


model8 <- mblogit(formula = treat_dur_cat ~ sex + age + inpat_id + emp.type + elix_sum, random = ~ 1 | pragmaid, data = final_data)
getSummary.mblogit(model8) 
add_model_summary(model8, "Model 8") # elix_sum als wichtiger Prädiktor

# ist char_sum ein besserer Prädiktor?
model9 <- mblogit(formula = treat_dur_cat ~ sex + age + inpat_id + emp.type + char_sum, random = ~ 1 | pragmaid, data = final_data)
getSummary.mblogit(model9)
add_model_summary(model9, "Model 9") # char_sum passt schlechter als elix_sum, ist aber auch signifikant

model10 <- mblogit(formula = treat_dur_cat ~ sex + age + inpat_id + emp.type + elix_sum + fost.degree_bin, random = ~ 1 | pragmaid, data = final_data)
getSummary.mblogit(model10)
add_model_summary(model10, "Model 10") # keine Verbesserung gegenüber Modell 8

model11 <- mblogit(formula = treat_dur_cat ~ sex + age + inpat_id + emp.type + elix_sum + ndistinctATClevel2, random = ~ 1 | pragmaid, data = final_data)
getSummary.mblogit(model11)
add_model_summary(model11, "Model 11") 

#find the best fitting model
choose_best_model <- function(summary_df, criterion) {
  if (!criterion %in% names(summary_df)) {
    stop("Ungültiges Kriterium. Wähle entweder 'Deviance', 'AIC' oder 'BIC'.")
  }
  best_model_row <- summary_df[which.min(summary_df[[criterion]]), ]
  return(best_model_row)
}

choose_best_model(model_summaries, "BIC") #Model 1 (Intercept) hat den besten fit
choose_best_model(model_summaries, "AIC") #Model 8 hat den besten fit
choose_best_model(model_summaries, "Deviance") #Model 11 hat den besten fit

``` 
### Behandlungsdauer als AV

```{r create vars}
#qwt_inpat <- qwt_inpat %>%
#  mutate(treat_dur_cat = factor(case_when(
#  #more than or 21 days in treatment
#  n.days >= 21 ~ 3,
#  #between 7 and 20 days (inclusive)
#  n.days >= 7 & n.days < 21 ~ 2,
#  #between 0 and 6 days (inclusive)
#  n.days >= 0 & n.days < 7 ~ 1,
#  TRUE ~ NA_real_), levels = c(1, 2, 3), labels = c("1-6 Tage","7-20 Tage", "21+ Tage")))

#check distribution
#ggplot(qwt_inpat, aes(x = treat_dur_cat)) + geom_bar() + theme(axis.text.x = element_text(angle = 25, hjust = 1)) + facet_wrap(~dataset)

```
# Check how results would change when excluding n.days_cat
```{r exclude n.days_cat}
model14.2 <- glmmTMB(unpl_drop ~ sex + age_cent + inpat_id_cent+ nationality + emp.type + elix_sum_cent + fost.degree_bin + ndistinctATClevel2_cent + QWT_count_before_INPAT_cent + treat_dur_cat + REHA_count_before_INPAT_cent + inpat_id_cent*age_cent + (1|pragmaid), family = "binomial", data = final_data) 

summary(model14.2) 
summary(best_model) #elixsum signifikant, in model mit treat_dur_cat nicht signifikant, QWT_count_before_INPAT_cent und age_cent:inpat_id_cent knapp nicht mehr signifikant
```
